2023-10-22 01:51:18,525 Iteration 1
2023-10-22 02:32:15,422 (Self-play) Number of new training examples: 5066
2023-10-22 02:32:15,422 (Self-play) Number of total training examples: 5066
2023-10-22 02:32:15,422 (Self-play) Model 1 wins: 0. Draws: 10. Model 2 wins: 90
2023-10-22 02:32:16,820 (Training) Epoch: 1. Total loss: 2.576. Value loss: 0.609. Policy accuracy: 0.222
2023-10-22 02:32:17,890 (Training) Epoch: 2. Total loss: 2.074. Value loss: 0.120. Policy accuracy: 0.243
2023-10-22 02:32:18,968 (Training) Epoch: 3. Total loss: 1.974. Value loss: 0.038. Policy accuracy: 0.292
2023-10-22 02:32:20,050 (Training) Epoch: 4. Total loss: 1.955. Value loss: 0.034. Policy accuracy: 0.335
2023-10-22 02:32:21,138 (Training) Epoch: 5. Total loss: 1.908. Value loss: 0.007. Policy accuracy: 0.369
2023-10-22 02:32:22,232 (Training) Epoch: 6. Total loss: 1.880. Value loss: 0.006. Policy accuracy: 0.419
2023-10-22 02:32:23,281 (Training) Epoch: 7. Total loss: 1.912. Value loss: 0.055. Policy accuracy: 0.453
2023-10-22 02:32:24,354 (Training) Epoch: 8. Total loss: 1.904. Value loss: 0.037. Policy accuracy: 0.419
2023-10-22 02:32:25,401 (Training) Epoch: 9. Total loss: 1.891. Value loss: 0.048. Policy accuracy: 0.458
2023-10-22 02:32:26,505 (Training) Epoch: 10. Total loss: 1.812. Value loss: 0.004. Policy accuracy: 0.494
2023-10-22 02:50:09,067 (Evaluation) Win rate: 0.2
2023-10-22 02:50:09,067 (Evaluation) Model 1 wins: 29. Draws: 3. Model 2 wins: 8
2023-10-22 02:50:09,077 (Evaluation) Rejecting new model...
2023-10-22 02:50:09,102 

2023-10-22 02:50:09,103 Iteration 2
2023-10-22 03:32:12,222 (Self-play) Number of new training examples: 5244
2023-10-22 03:32:12,222 (Self-play) Number of total training examples: 10310
2023-10-22 03:32:12,222 (Self-play) Model 1 wins: 0. Draws: 9. Model 2 wins: 91
2023-10-22 03:32:14,632 (Training) Epoch: 1. Total loss: 2.689. Value loss: 0.730. Policy accuracy: 0.262
2023-10-22 03:32:16,963 (Training) Epoch: 2. Total loss: 2.362. Value loss: 0.421. Policy accuracy: 0.310
2023-10-22 03:32:19,390 (Training) Epoch: 3. Total loss: 2.285. Value loss: 0.364. Policy accuracy: 0.333
2023-10-22 03:32:21,750 (Training) Epoch: 4. Total loss: 2.237. Value loss: 0.327. Policy accuracy: 0.349
2023-10-22 03:32:24,119 (Training) Epoch: 5. Total loss: 2.198. Value loss: 0.305. Policy accuracy: 0.361
2023-10-22 03:32:26,449 (Training) Epoch: 6. Total loss: 2.142. Value loss: 0.267. Policy accuracy: 0.389
2023-10-22 03:32:28,709 (Training) Epoch: 7. Total loss: 2.150. Value loss: 0.289. Policy accuracy: 0.414
2023-10-22 03:32:30,980 (Training) Epoch: 8. Total loss: 2.112. Value loss: 0.274. Policy accuracy: 0.442
2023-10-22 03:32:33,204 (Training) Epoch: 9. Total loss: 2.064. Value loss: 0.242. Policy accuracy: 0.467
2023-10-22 03:32:35,470 (Training) Epoch: 10. Total loss: 2.046. Value loss: 0.246. Policy accuracy: 0.489
2023-10-22 03:52:16,654 (Evaluation) Win rate: 0.225
2023-10-22 03:52:16,654 (Evaluation) Model 1 wins: 27. Draws: 4. Model 2 wins: 9
2023-10-22 03:52:16,664 (Evaluation) Rejecting new model...
2023-10-22 03:52:16,687 

2023-10-22 03:52:16,688 Iteration 3
2023-10-22 04:37:01,062 (Self-play) Number of new training examples: 5514
2023-10-22 04:37:01,062 (Self-play) Number of total training examples: 15824
2023-10-22 04:37:01,062 (Self-play) Model 1 wins: 0. Draws: 13. Model 2 wins: 87
2023-10-22 04:37:04,869 (Training) Epoch: 1. Total loss: 2.436. Value loss: 0.489. Policy accuracy: 0.282
2023-10-22 04:37:08,224 (Training) Epoch: 2. Total loss: 2.242. Value loss: 0.322. Policy accuracy: 0.324
2023-10-22 04:37:11,656 (Training) Epoch: 3. Total loss: 2.156. Value loss: 0.262. Policy accuracy: 0.356
2023-10-22 04:37:15,177 (Training) Epoch: 4. Total loss: 2.107. Value loss: 0.238. Policy accuracy: 0.394
2023-10-22 04:37:18,881 (Training) Epoch: 5. Total loss: 2.068. Value loss: 0.218. Policy accuracy: 0.425
2023-10-22 04:37:22,789 (Training) Epoch: 6. Total loss: 2.033. Value loss: 0.211. Policy accuracy: 0.472
2023-10-22 04:37:26,493 (Training) Epoch: 7. Total loss: 1.994. Value loss: 0.201. Policy accuracy: 0.505
2023-10-22 04:37:29,878 (Training) Epoch: 8. Total loss: 1.951. Value loss: 0.187. Policy accuracy: 0.535
2023-10-22 04:37:33,175 (Training) Epoch: 9. Total loss: 1.916. Value loss: 0.176. Policy accuracy: 0.564
2023-10-22 04:37:36,469 (Training) Epoch: 10. Total loss: 1.894. Value loss: 0.178. Policy accuracy: 0.589
2023-10-22 04:56:33,980 (Evaluation) Win rate: 0.25
2023-10-22 04:56:33,980 (Evaluation) Model 1 wins: 25. Draws: 5. Model 2 wins: 10
2023-10-22 04:56:33,990 (Evaluation) Rejecting new model...
2023-10-22 04:56:34,014 

2023-10-22 04:56:34,015 Iteration 4
2023-10-22 05:38:16,506 (Self-play) Number of new training examples: 5114
2023-10-22 05:38:16,506 (Self-play) Number of total training examples: 20938
2023-10-22 05:38:16,506 (Self-play) Model 1 wins: 0. Draws: 9. Model 2 wins: 91
2023-10-22 05:38:21,301 (Training) Epoch: 1. Total loss: 2.512. Value loss: 0.563. Policy accuracy: 0.287
2023-10-22 05:38:26,055 (Training) Epoch: 2. Total loss: 2.275. Value loss: 0.362. Policy accuracy: 0.340
2023-10-22 05:38:30,985 (Training) Epoch: 3. Total loss: 2.198. Value loss: 0.308. Policy accuracy: 0.356
2023-10-22 05:38:35,618 (Training) Epoch: 4. Total loss: 2.138. Value loss: 0.278. Policy accuracy: 0.400
2023-10-22 05:38:40,102 (Training) Epoch: 5. Total loss: 2.089. Value loss: 0.255. Policy accuracy: 0.439
2023-10-22 05:38:44,569 (Training) Epoch: 6. Total loss: 2.041. Value loss: 0.233. Policy accuracy: 0.466
2023-10-22 05:38:49,073 (Training) Epoch: 7. Total loss: 2.007. Value loss: 0.227. Policy accuracy: 0.503
2023-10-22 05:38:53,886 (Training) Epoch: 8. Total loss: 1.978. Value loss: 0.222. Policy accuracy: 0.534
2023-10-22 05:38:58,710 (Training) Epoch: 9. Total loss: 1.940. Value loss: 0.209. Policy accuracy: 0.556
2023-10-22 05:39:03,490 (Training) Epoch: 10. Total loss: 1.914. Value loss: 0.198. Policy accuracy: 0.571
2023-10-22 05:58:48,064 (Evaluation) Win rate: 0.175
2023-10-22 05:58:48,064 (Evaluation) Model 1 wins: 29. Draws: 4. Model 2 wins: 7
2023-10-22 05:58:48,074 (Evaluation) Rejecting new model...
2023-10-22 05:58:48,097 

2023-10-22 05:58:48,099 Iteration 5
2023-10-22 06:41:10,173 (Self-play) Number of new training examples: 5252
2023-10-22 06:41:10,174 (Self-play) Number of total training examples: 26190
2023-10-22 06:41:10,174 (Self-play) Model 1 wins: 0. Draws: 8. Model 2 wins: 92
2023-10-22 06:41:15,938 (Training) Epoch: 1. Total loss: 2.513. Value loss: 0.571. Policy accuracy: 0.289
2023-10-22 06:41:21,675 (Training) Epoch: 2. Total loss: 2.264. Value loss: 0.356. Policy accuracy: 0.333
2023-10-22 06:41:27,475 (Training) Epoch: 3. Total loss: 2.176. Value loss: 0.298. Policy accuracy: 0.375
2023-10-22 06:41:33,218 (Training) Epoch: 4. Total loss: 2.117. Value loss: 0.262. Policy accuracy: 0.408
2023-10-22 06:41:39,090 (Training) Epoch: 5. Total loss: 2.072. Value loss: 0.248. Policy accuracy: 0.448
2023-10-22 06:41:44,740 (Training) Epoch: 6. Total loss: 2.030. Value loss: 0.229. Policy accuracy: 0.475
2023-10-22 06:41:50,330 (Training) Epoch: 7. Total loss: 1.988. Value loss: 0.215. Policy accuracy: 0.506
2023-10-22 06:41:56,095 (Training) Epoch: 8. Total loss: 1.963. Value loss: 0.208. Policy accuracy: 0.520
2023-10-22 06:42:02,351 (Training) Epoch: 9. Total loss: 1.940. Value loss: 0.206. Policy accuracy: 0.546
2023-10-22 06:42:08,447 (Training) Epoch: 10. Total loss: 1.908. Value loss: 0.199. Policy accuracy: 0.577
2023-10-22 07:00:57,601 (Evaluation) Win rate: 0.375
2023-10-22 07:00:57,601 (Evaluation) Model 1 wins: 19. Draws: 6. Model 2 wins: 15
2023-10-22 07:00:57,613 (Evaluation) Rejecting new model...
2023-10-22 07:00:57,637 

2023-10-22 07:00:57,637 Iteration 6
2023-10-22 07:47:06,490 (Self-play) Number of new training examples: 5856
2023-10-22 07:47:06,490 (Self-play) Number of total training examples: 32046
2023-10-22 07:47:06,490 (Self-play) Model 1 wins: 0. Draws: 13. Model 2 wins: 87
2023-10-22 07:47:13,494 (Training) Epoch: 1. Total loss: 2.599. Value loss: 0.659. Policy accuracy: 0.294
2023-10-22 07:47:20,335 (Training) Epoch: 2. Total loss: 2.344. Value loss: 0.444. Policy accuracy: 0.346
2023-10-22 07:47:27,747 (Training) Epoch: 3. Total loss: 2.254. Value loss: 0.380. Policy accuracy: 0.380
2023-10-22 07:47:35,082 (Training) Epoch: 4. Total loss: 2.192. Value loss: 0.345. Policy accuracy: 0.419
2023-10-22 07:47:41,820 (Training) Epoch: 5. Total loss: 2.133. Value loss: 0.311. Policy accuracy: 0.445
2023-10-22 07:47:48,753 (Training) Epoch: 6. Total loss: 2.093. Value loss: 0.301. Policy accuracy: 0.477
2023-10-22 07:47:56,102 (Training) Epoch: 7. Total loss: 2.052. Value loss: 0.281. Policy accuracy: 0.499
2023-10-22 07:48:03,381 (Training) Epoch: 8. Total loss: 2.002. Value loss: 0.262. Policy accuracy: 0.535
2023-10-22 07:48:10,400 (Training) Epoch: 9. Total loss: 1.974. Value loss: 0.252. Policy accuracy: 0.553
2023-10-22 07:48:17,233 (Training) Epoch: 10. Total loss: 1.944. Value loss: 0.246. Policy accuracy: 0.583
2023-10-22 08:09:36,854 (Evaluation) Win rate: 0.225
2023-10-22 08:09:36,854 (Evaluation) Model 1 wins: 26. Draws: 5. Model 2 wins: 9
2023-10-22 08:09:36,864 (Evaluation) Rejecting new model...
2023-10-22 08:09:36,888 

2023-10-22 08:09:36,889 Iteration 7
2023-10-22 08:49:39,758 (Self-play) Number of new training examples: 4944
2023-10-22 08:49:39,758 (Self-play) Number of total training examples: 36990
2023-10-22 08:49:39,758 (Self-play) Model 1 wins: 0. Draws: 7. Model 2 wins: 93
2023-10-22 08:49:48,144 (Training) Epoch: 1. Total loss: 2.608. Value loss: 0.672. Policy accuracy: 0.297
2023-10-22 08:49:56,456 (Training) Epoch: 2. Total loss: 2.341. Value loss: 0.443. Policy accuracy: 0.346
2023-10-22 08:50:04,202 (Training) Epoch: 3. Total loss: 2.238. Value loss: 0.372. Policy accuracy: 0.390
2023-10-22 08:50:12,461 (Training) Epoch: 4. Total loss: 2.174. Value loss: 0.338. Policy accuracy: 0.432
2023-10-22 08:50:20,854 (Training) Epoch: 5. Total loss: 2.114. Value loss: 0.309. Policy accuracy: 0.463
2023-10-22 08:50:28,978 (Training) Epoch: 6. Total loss: 2.078. Value loss: 0.293. Policy accuracy: 0.482
2023-10-22 08:50:37,016 (Training) Epoch: 7. Total loss: 2.038. Value loss: 0.280. Policy accuracy: 0.512
2023-10-22 08:50:45,005 (Training) Epoch: 8. Total loss: 2.000. Value loss: 0.264. Policy accuracy: 0.537
2023-10-22 08:50:53,457 (Training) Epoch: 9. Total loss: 1.968. Value loss: 0.256. Policy accuracy: 0.568
2023-10-22 08:51:01,386 (Training) Epoch: 10. Total loss: 1.941. Value loss: 0.243. Policy accuracy: 0.578
2023-10-22 09:10:47,770 (Evaluation) Win rate: 0.35
2023-10-22 09:10:47,770 (Evaluation) Model 1 wins: 24. Draws: 2. Model 2 wins: 14
2023-10-22 09:10:47,786 (Evaluation) Rejecting new model...
2023-10-22 09:10:47,810 

2023-10-22 09:10:47,810 Iteration 8
2023-10-22 09:51:25,627 (Self-play) Number of new training examples: 5024
2023-10-22 09:51:25,627 (Self-play) Number of total training examples: 42014
2023-10-22 09:51:25,627 (Self-play) Model 1 wins: 0. Draws: 6. Model 2 wins: 94
2023-10-22 09:51:34,960 (Training) Epoch: 1. Total loss: 2.602. Value loss: 0.672. Policy accuracy: 0.308
2023-10-22 09:51:44,501 (Training) Epoch: 2. Total loss: 2.326. Value loss: 0.441. Policy accuracy: 0.365
2023-10-22 09:51:53,596 (Training) Epoch: 3. Total loss: 2.225. Value loss: 0.375. Policy accuracy: 0.413
2023-10-22 09:52:02,593 (Training) Epoch: 4. Total loss: 2.149. Value loss: 0.327. Policy accuracy: 0.440
2023-10-22 09:52:12,163 (Training) Epoch: 5. Total loss: 2.098. Value loss: 0.301. Policy accuracy: 0.469
2023-10-22 09:52:21,439 (Training) Epoch: 6. Total loss: 2.063. Value loss: 0.286. Policy accuracy: 0.489
2023-10-22 09:52:30,298 (Training) Epoch: 7. Total loss: 2.015. Value loss: 0.266. Policy accuracy: 0.520
2023-10-22 09:52:40,073 (Training) Epoch: 8. Total loss: 1.984. Value loss: 0.256. Policy accuracy: 0.545
2023-10-22 09:52:49,237 (Training) Epoch: 9. Total loss: 1.964. Value loss: 0.252. Policy accuracy: 0.564
2023-10-22 09:52:58,561 (Training) Epoch: 10. Total loss: 1.939. Value loss: 0.245. Policy accuracy: 0.578
2023-10-22 10:11:11,535 (Evaluation) Win rate: 0.2
2023-10-22 10:11:11,535 (Evaluation) Model 1 wins: 29. Draws: 3. Model 2 wins: 8
2023-10-22 10:11:11,545 (Evaluation) Rejecting new model...
2023-10-22 10:11:11,567 

2023-10-22 10:11:11,568 Iteration 9
2023-10-22 10:53:33,175 (Self-play) Number of new training examples: 5168
2023-10-22 10:53:33,176 (Self-play) Number of total training examples: 47182
2023-10-22 10:53:33,176 (Self-play) Model 1 wins: 0. Draws: 6. Model 2 wins: 94
2023-10-22 10:53:44,109 (Training) Epoch: 1. Total loss: 2.597. Value loss: 0.666. Policy accuracy: 0.307
2023-10-22 10:53:54,446 (Training) Epoch: 2. Total loss: 2.309. Value loss: 0.424. Policy accuracy: 0.368
2023-10-22 10:54:04,704 (Training) Epoch: 3. Total loss: 2.217. Value loss: 0.366. Policy accuracy: 0.412
2023-10-22 10:54:15,424 (Training) Epoch: 4. Total loss: 2.145. Value loss: 0.324. Policy accuracy: 0.444
2023-10-22 10:54:26,069 (Training) Epoch: 5. Total loss: 2.095. Value loss: 0.300. Policy accuracy: 0.470
2023-10-22 10:54:36,151 (Training) Epoch: 6. Total loss: 2.045. Value loss: 0.278. Policy accuracy: 0.503
2023-10-22 10:54:47,033 (Training) Epoch: 7. Total loss: 2.011. Value loss: 0.266. Policy accuracy: 0.525
2023-10-22 10:54:57,045 (Training) Epoch: 8. Total loss: 1.980. Value loss: 0.254. Policy accuracy: 0.547
2023-10-22 10:55:07,954 (Training) Epoch: 9. Total loss: 1.954. Value loss: 0.248. Policy accuracy: 0.570
2023-10-22 10:55:18,655 (Training) Epoch: 10. Total loss: 1.930. Value loss: 0.240. Policy accuracy: 0.584
2023-10-22 11:13:28,042 (Evaluation) Win rate: 0.6
2023-10-22 11:13:28,043 (Evaluation) Model 1 wins: 12. Draws: 4. Model 2 wins: 24
2023-10-22 11:13:28,052 (Evaluation) Accepting new model...
2023-10-22 11:13:28,075 

2023-10-22 11:13:28,076 Iteration 10
2023-10-22 11:56:32,991 (Self-play) Number of new training examples: 6498
2023-10-22 11:56:32,992 (Self-play) Number of total training examples: 53680
2023-10-22 11:56:32,992 (Self-play) Model 1 wins: 0. Draws: 28. Model 2 wins: 72
2023-10-22 11:56:44,743 (Training) Epoch: 1. Total loss: 1.916. Value loss: 0.232. Policy accuracy: 0.579
2023-10-22 11:56:56,576 (Training) Epoch: 2. Total loss: 1.884. Value loss: 0.212. Policy accuracy: 0.591
2023-10-22 11:57:08,317 (Training) Epoch: 3. Total loss: 1.870. Value loss: 0.206. Policy accuracy: 0.599
2023-10-22 11:57:19,944 (Training) Epoch: 4. Total loss: 1.860. Value loss: 0.206. Policy accuracy: 0.609
2023-10-22 11:57:32,136 (Training) Epoch: 5. Total loss: 1.841. Value loss: 0.194. Policy accuracy: 0.613
2023-10-22 11:57:43,683 (Training) Epoch: 6. Total loss: 1.828. Value loss: 0.192. Policy accuracy: 0.627
2023-10-22 11:57:55,555 (Training) Epoch: 7. Total loss: 1.823. Value loss: 0.189. Policy accuracy: 0.627
2023-10-22 11:58:07,228 (Training) Epoch: 8. Total loss: 1.820. Value loss: 0.192. Policy accuracy: 0.635
2023-10-22 11:58:19,022 (Training) Epoch: 9. Total loss: 1.804. Value loss: 0.184. Policy accuracy: 0.642
2023-10-22 11:58:31,094 (Training) Epoch: 10. Total loss: 1.799. Value loss: 0.183. Policy accuracy: 0.647
2023-10-22 12:14:27,134 (Evaluation) Win rate: 0.275
2023-10-22 12:14:27,134 (Evaluation) Model 1 wins: 20. Draws: 9. Model 2 wins: 11
2023-10-22 12:14:27,145 (Evaluation) Rejecting new model...
2023-10-22 12:14:27,177 

2023-10-22 12:14:27,178 Iteration 11
2023-10-22 12:56:47,936 (Self-play) Number of new training examples: 6760
2023-10-22 12:56:47,937 (Self-play) Number of total training examples: 60440
2023-10-22 12:56:47,937 (Self-play) Model 1 wins: 0. Draws: 32. Model 2 wins: 68
2023-10-22 12:57:00,916 (Training) Epoch: 1. Total loss: 2.026. Value loss: 0.343. Policy accuracy: 0.567
2023-10-22 12:57:14,654 (Training) Epoch: 2. Total loss: 1.950. Value loss: 0.282. Policy accuracy: 0.581
2023-10-22 12:57:27,451 (Training) Epoch: 3. Total loss: 1.921. Value loss: 0.267. Policy accuracy: 0.594
2023-10-22 12:57:41,010 (Training) Epoch: 4. Total loss: 1.899. Value loss: 0.254. Policy accuracy: 0.604
2023-10-22 12:57:54,168 (Training) Epoch: 5. Total loss: 1.881. Value loss: 0.244. Policy accuracy: 0.612
2023-10-22 12:58:07,547 (Training) Epoch: 6. Total loss: 1.869. Value loss: 0.238. Policy accuracy: 0.619
2023-10-22 12:58:20,552 (Training) Epoch: 7. Total loss: 1.868. Value loss: 0.244. Policy accuracy: 0.624
2023-10-22 12:58:34,324 (Training) Epoch: 8. Total loss: 1.855. Value loss: 0.235. Policy accuracy: 0.629
2023-10-22 12:58:47,787 (Training) Epoch: 9. Total loss: 1.842. Value loss: 0.228. Policy accuracy: 0.634
2023-10-22 12:59:01,004 (Training) Epoch: 10. Total loss: 1.840. Value loss: 0.230. Policy accuracy: 0.637
2023-10-22 13:13:49,116 (Evaluation) Win rate: 0.375
2023-10-22 13:13:49,116 (Evaluation) Model 1 wins: 20. Draws: 5. Model 2 wins: 15
2023-10-22 13:13:49,126 (Evaluation) Rejecting new model...
2023-10-22 13:13:49,156 

2023-10-22 13:13:49,157 Iteration 12
2023-10-22 13:53:48,777 (Self-play) Number of new training examples: 6400
2023-10-22 13:53:48,778 (Self-play) Number of total training examples: 66840
2023-10-22 13:53:48,778 (Self-play) Model 1 wins: 0. Draws: 34. Model 2 wins: 66
2023-10-22 13:54:03,741 (Training) Epoch: 1. Total loss: 2.079. Value loss: 0.397. Policy accuracy: 0.560
2023-10-22 13:54:18,618 (Training) Epoch: 2. Total loss: 1.988. Value loss: 0.323. Policy accuracy: 0.576
2023-10-22 13:54:33,365 (Training) Epoch: 3. Total loss: 1.950. Value loss: 0.302. Policy accuracy: 0.591
2023-10-22 13:54:47,888 (Training) Epoch: 4. Total loss: 1.924. Value loss: 0.286. Policy accuracy: 0.601
2023-10-22 13:55:02,843 (Training) Epoch: 5. Total loss: 1.907. Value loss: 0.273. Policy accuracy: 0.609
2023-10-22 13:55:17,847 (Training) Epoch: 6. Total loss: 1.897. Value loss: 0.271. Policy accuracy: 0.613
2023-10-22 13:55:32,547 (Training) Epoch: 7. Total loss: 1.885. Value loss: 0.265. Policy accuracy: 0.622
2023-10-22 13:55:47,493 (Training) Epoch: 8. Total loss: 1.863. Value loss: 0.253. Policy accuracy: 0.629
2023-10-22 13:56:02,344 (Training) Epoch: 9. Total loss: 1.862. Value loss: 0.252. Policy accuracy: 0.630
2023-10-22 13:56:17,429 (Training) Epoch: 10. Total loss: 1.855. Value loss: 0.250. Policy accuracy: 0.637
2023-10-22 14:11:54,373 (Evaluation) Win rate: 0.125
2023-10-22 14:11:54,373 (Evaluation) Model 1 wins: 27. Draws: 8. Model 2 wins: 5
2023-10-22 14:11:54,384 (Evaluation) Rejecting new model...
2023-10-22 14:11:54,407 

2023-10-22 14:11:54,408 Iteration 13
2023-10-22 14:54:24,235 (Self-play) Number of new training examples: 6394
2023-10-22 14:54:24,236 (Self-play) Number of total training examples: 73234
2023-10-22 14:54:24,236 (Self-play) Model 1 wins: 0. Draws: 29. Model 2 wins: 71
2023-10-22 14:54:40,624 (Training) Epoch: 1. Total loss: 2.056. Value loss: 0.376. Policy accuracy: 0.558
2023-10-22 14:54:57,127 (Training) Epoch: 2. Total loss: 1.971. Value loss: 0.312. Policy accuracy: 0.578
2023-10-22 14:55:12,735 (Training) Epoch: 3. Total loss: 1.934. Value loss: 0.286. Policy accuracy: 0.590
2023-10-22 14:55:29,370 (Training) Epoch: 4. Total loss: 1.913. Value loss: 0.275. Policy accuracy: 0.597
2023-10-22 14:55:45,221 (Training) Epoch: 5. Total loss: 1.889. Value loss: 0.261. Policy accuracy: 0.608
2023-10-22 14:56:01,478 (Training) Epoch: 6. Total loss: 1.876. Value loss: 0.256. Policy accuracy: 0.615
2023-10-22 14:56:17,727 (Training) Epoch: 7. Total loss: 1.866. Value loss: 0.251. Policy accuracy: 0.620
2023-10-22 14:56:34,044 (Training) Epoch: 8. Total loss: 1.852. Value loss: 0.244. Policy accuracy: 0.628
2023-10-22 14:56:50,132 (Training) Epoch: 9. Total loss: 1.842. Value loss: 0.238. Policy accuracy: 0.630
2023-10-22 14:57:06,049 (Training) Epoch: 10. Total loss: 1.830. Value loss: 0.231. Policy accuracy: 0.636
2023-10-22 15:11:55,531 (Evaluation) Win rate: 0.7
2023-10-22 15:11:55,531 (Evaluation) Model 1 wins: 12. Draws: 0. Model 2 wins: 28
2023-10-22 15:11:55,541 (Evaluation) Accepting new model...
2023-10-22 15:11:55,567 

2023-10-22 15:11:55,567 Iteration 14
2023-10-22 15:52:23,856 (Self-play) Number of new training examples: 6812
2023-10-22 15:52:23,856 (Self-play) Number of total training examples: 80046
2023-10-22 15:52:23,856 (Self-play) Model 1 wins: 0. Draws: 39. Model 2 wins: 61
2023-10-22 15:52:42,148 (Training) Epoch: 1. Total loss: 1.828. Value loss: 0.228. Policy accuracy: 0.630
2023-10-22 15:52:59,562 (Training) Epoch: 2. Total loss: 1.818. Value loss: 0.222. Policy accuracy: 0.632
2023-10-22 15:53:17,279 (Training) Epoch: 3. Total loss: 1.798. Value loss: 0.210. Policy accuracy: 0.643
2023-10-22 15:53:35,218 (Training) Epoch: 4. Total loss: 1.796. Value loss: 0.211. Policy accuracy: 0.643
2023-10-22 15:53:52,668 (Training) Epoch: 5. Total loss: 1.792. Value loss: 0.211. Policy accuracy: 0.650
2023-10-22 15:54:10,681 (Training) Epoch: 6. Total loss: 1.783. Value loss: 0.206. Policy accuracy: 0.654
2023-10-22 15:54:28,183 (Training) Epoch: 7. Total loss: 1.773. Value loss: 0.201. Policy accuracy: 0.653
2023-10-22 15:54:46,210 (Training) Epoch: 8. Total loss: 1.772. Value loss: 0.205. Policy accuracy: 0.655
2023-10-22 15:55:04,033 (Training) Epoch: 9. Total loss: 1.767. Value loss: 0.200. Policy accuracy: 0.655
2023-10-22 15:55:21,492 (Training) Epoch: 10. Total loss: 1.764. Value loss: 0.200. Policy accuracy: 0.657
2023-10-22 16:16:31,978 (Evaluation) Win rate: 0.55
2023-10-22 16:16:31,978 (Evaluation) Model 1 wins: 17. Draws: 1. Model 2 wins: 22
2023-10-22 16:16:31,988 (Evaluation) Accepting new model...
2023-10-22 16:16:32,012 

2023-10-22 16:16:32,013 Iteration 15
2023-10-22 16:58:00,536 (Self-play) Number of new training examples: 6838
2023-10-22 16:58:00,536 (Self-play) Number of total training examples: 86884
2023-10-22 16:58:00,536 (Self-play) Model 1 wins: 0. Draws: 44. Model 2 wins: 56
2023-10-22 16:58:21,062 (Training) Epoch: 1. Total loss: 1.761. Value loss: 0.198. Policy accuracy: 0.654
2023-10-22 16:58:41,127 (Training) Epoch: 2. Total loss: 1.747. Value loss: 0.187. Policy accuracy: 0.658
2023-10-22 16:59:01,433 (Training) Epoch: 3. Total loss: 1.741. Value loss: 0.184. Policy accuracy: 0.663
2023-10-22 16:59:22,040 (Training) Epoch: 4. Total loss: 1.737. Value loss: 0.182. Policy accuracy: 0.664
2023-10-22 16:59:42,907 (Training) Epoch: 5. Total loss: 1.733. Value loss: 0.183. Policy accuracy: 0.669
2023-10-22 17:00:04,407 (Training) Epoch: 6. Total loss: 1.726. Value loss: 0.179. Policy accuracy: 0.673
2023-10-22 17:00:25,238 (Training) Epoch: 7. Total loss: 1.724. Value loss: 0.178. Policy accuracy: 0.674
2023-10-22 17:00:46,543 (Training) Epoch: 8. Total loss: 1.725. Value loss: 0.181. Policy accuracy: 0.675
2023-10-22 17:01:07,172 (Training) Epoch: 9. Total loss: 1.716. Value loss: 0.178. Policy accuracy: 0.683
2023-10-22 17:01:27,829 (Training) Epoch: 10. Total loss: 1.717. Value loss: 0.176. Policy accuracy: 0.680
2023-10-22 17:18:56,917 (Evaluation) Win rate: 0.9
2023-10-22 17:18:56,917 (Evaluation) Model 1 wins: 4. Draws: 0. Model 2 wins: 36
2023-10-22 17:18:56,929 (Evaluation) Accepting new model...
2023-10-22 17:18:56,954 

2023-10-22 17:18:56,955 Iteration 16
2023-10-22 18:01:38,722 (Self-play) Number of new training examples: 7308
2023-10-22 18:01:38,722 (Self-play) Number of total training examples: 94192
2023-10-22 18:01:38,722 (Self-play) Model 1 wins: 0. Draws: 58. Model 2 wins: 42
2023-10-22 18:01:59,942 (Training) Epoch: 1. Total loss: 1.755. Value loss: 0.216. Policy accuracy: 0.680
2023-10-22 18:02:21,337 (Training) Epoch: 2. Total loss: 1.731. Value loss: 0.196. Policy accuracy: 0.684
2023-10-22 18:02:42,359 (Training) Epoch: 3. Total loss: 1.721. Value loss: 0.189. Policy accuracy: 0.686
2023-10-22 18:03:03,157 (Training) Epoch: 4. Total loss: 1.715. Value loss: 0.186. Policy accuracy: 0.689
2023-10-22 18:03:24,209 (Training) Epoch: 5. Total loss: 1.713. Value loss: 0.184. Policy accuracy: 0.690
2023-10-22 18:03:45,259 (Training) Epoch: 6. Total loss: 1.708. Value loss: 0.181. Policy accuracy: 0.693
2023-10-22 18:04:06,064 (Training) Epoch: 7. Total loss: 1.707. Value loss: 0.180. Policy accuracy: 0.693
2023-10-22 18:04:27,073 (Training) Epoch: 8. Total loss: 1.700. Value loss: 0.178. Policy accuracy: 0.697
2023-10-22 18:04:48,233 (Training) Epoch: 9. Total loss: 1.698. Value loss: 0.177. Policy accuracy: 0.700
2023-10-22 18:05:09,463 (Training) Epoch: 10. Total loss: 1.693. Value loss: 0.174. Policy accuracy: 0.701
2023-10-22 18:20:01,876 (Evaluation) Win rate: 0.25
2023-10-22 18:20:01,877 (Evaluation) Model 1 wins: 26. Draws: 4. Model 2 wins: 10
2023-10-22 18:20:01,886 (Evaluation) Rejecting new model...
2023-10-22 18:20:01,910 

2023-10-22 18:20:01,911 Iteration 17
2023-10-22 19:02:42,746 (Self-play) Number of new training examples: 7282
2023-10-22 19:02:42,746 (Self-play) Number of total training examples: 101474
2023-10-22 19:02:42,746 (Self-play) Model 1 wins: 0. Draws: 59. Model 2 wins: 41
2023-10-22 19:03:05,359 (Training) Epoch: 1. Total loss: 1.750. Value loss: 0.209. Policy accuracy: 0.675
2023-10-22 19:03:27,788 (Training) Epoch: 2. Total loss: 1.727. Value loss: 0.190. Policy accuracy: 0.680
2023-10-22 19:03:50,455 (Training) Epoch: 3. Total loss: 1.720. Value loss: 0.186. Policy accuracy: 0.682
2023-10-22 19:04:12,803 (Training) Epoch: 4. Total loss: 1.713. Value loss: 0.183. Policy accuracy: 0.685
2023-10-22 19:04:35,276 (Training) Epoch: 5. Total loss: 1.704. Value loss: 0.179. Policy accuracy: 0.693
2023-10-22 19:04:57,534 (Training) Epoch: 6. Total loss: 1.704. Value loss: 0.178. Policy accuracy: 0.691
2023-10-22 19:05:20,021 (Training) Epoch: 7. Total loss: 1.695. Value loss: 0.173. Policy accuracy: 0.695
2023-10-22 19:05:42,583 (Training) Epoch: 8. Total loss: 1.699. Value loss: 0.175. Policy accuracy: 0.694
2023-10-22 19:06:05,235 (Training) Epoch: 9. Total loss: 1.688. Value loss: 0.168. Policy accuracy: 0.697
2023-10-22 19:06:27,679 (Training) Epoch: 10. Total loss: 1.685. Value loss: 0.170. Policy accuracy: 0.703
2023-10-22 19:18:54,474 (Evaluation) Win rate: 0.425
2023-10-22 19:18:54,474 (Evaluation) Model 1 wins: 21. Draws: 2. Model 2 wins: 17
2023-10-22 19:18:54,485 (Evaluation) Rejecting new model...
2023-10-22 19:18:54,510 

2023-10-22 19:18:54,512 Iteration 18
2023-10-22 20:01:41,230 (Self-play) Number of new training examples: 7086
2023-10-22 20:01:41,230 (Self-play) Number of total training examples: 108560
2023-10-22 20:01:41,230 (Self-play) Model 1 wins: 0. Draws: 53. Model 2 wins: 47
2023-10-22 20:02:05,469 (Training) Epoch: 1. Total loss: 1.749. Value loss: 0.206. Policy accuracy: 0.670
2023-10-22 20:02:29,044 (Training) Epoch: 2. Total loss: 1.726. Value loss: 0.186. Policy accuracy: 0.674
2023-10-22 20:02:53,443 (Training) Epoch: 3. Total loss: 1.714. Value loss: 0.180. Policy accuracy: 0.680
2023-10-22 20:03:17,315 (Training) Epoch: 4. Total loss: 1.706. Value loss: 0.175. Policy accuracy: 0.683
2023-10-22 20:03:41,523 (Training) Epoch: 5. Total loss: 1.701. Value loss: 0.174. Policy accuracy: 0.688
2023-10-22 20:04:05,216 (Training) Epoch: 6. Total loss: 1.697. Value loss: 0.173. Policy accuracy: 0.690
2023-10-22 20:04:29,108 (Training) Epoch: 7. Total loss: 1.691. Value loss: 0.169. Policy accuracy: 0.694
2023-10-22 20:04:53,237 (Training) Epoch: 8. Total loss: 1.686. Value loss: 0.168. Policy accuracy: 0.697
2023-10-22 20:05:17,224 (Training) Epoch: 9. Total loss: 1.683. Value loss: 0.166. Policy accuracy: 0.700
2023-10-22 20:05:41,428 (Training) Epoch: 10. Total loss: 1.677. Value loss: 0.164. Policy accuracy: 0.703
2023-10-22 20:22:44,746 (Evaluation) Win rate: 0.575
2023-10-22 20:22:44,746 (Evaluation) Model 1 wins: 9. Draws: 8. Model 2 wins: 23
2023-10-22 20:22:44,756 (Evaluation) Accepting new model...
2023-10-22 20:22:44,780 

2023-10-22 20:22:44,782 Iteration 19
2023-10-22 21:00:43,414 (Self-play) Number of new training examples: 7076
2023-10-22 21:00:43,414 (Self-play) Number of total training examples: 115636
2023-10-22 21:00:43,414 (Self-play) Model 1 wins: 0. Draws: 60. Model 2 wins: 40
2023-10-22 21:01:09,309 (Training) Epoch: 1. Total loss: 1.677. Value loss: 0.162. Policy accuracy: 0.699
2023-10-22 21:01:34,679 (Training) Epoch: 2. Total loss: 1.674. Value loss: 0.161. Policy accuracy: 0.701
2023-10-22 21:01:59,943 (Training) Epoch: 3. Total loss: 1.670. Value loss: 0.159. Policy accuracy: 0.703
2023-10-22 21:02:25,261 (Training) Epoch: 4. Total loss: 1.664. Value loss: 0.154. Policy accuracy: 0.705
2023-10-22 21:02:50,674 (Training) Epoch: 5. Total loss: 1.660. Value loss: 0.155. Policy accuracy: 0.711
2023-10-22 21:03:15,901 (Training) Epoch: 6. Total loss: 1.661. Value loss: 0.155. Policy accuracy: 0.710
2023-10-22 21:03:41,452 (Training) Epoch: 7. Total loss: 1.657. Value loss: 0.155. Policy accuracy: 0.713
2023-10-22 21:04:07,158 (Training) Epoch: 8. Total loss: 1.650. Value loss: 0.152. Policy accuracy: 0.717
2023-10-22 21:04:32,505 (Training) Epoch: 9. Total loss: 1.649. Value loss: 0.150. Policy accuracy: 0.720
2023-10-22 21:04:57,875 (Training) Epoch: 10. Total loss: 1.648. Value loss: 0.151. Policy accuracy: 0.719
2023-10-22 21:19:25,992 (Evaluation) Win rate: 0.3
2023-10-22 21:19:25,992 (Evaluation) Model 1 wins: 24. Draws: 4. Model 2 wins: 12
2023-10-22 21:19:26,002 (Evaluation) Rejecting new model...
2023-10-22 21:19:26,027 

2023-10-22 21:19:26,028 Iteration 20
2023-10-22 21:57:41,325 (Self-play) Number of new training examples: 6922
2023-10-22 21:57:41,326 (Self-play) Number of total training examples: 122558
2023-10-22 21:57:41,326 (Self-play) Model 1 wins: 0. Draws: 60. Model 2 wins: 40
2023-10-22 21:58:08,217 (Training) Epoch: 1. Total loss: 1.721. Value loss: 0.207. Policy accuracy: 0.699
2023-10-22 21:58:35,026 (Training) Epoch: 2. Total loss: 1.704. Value loss: 0.191. Policy accuracy: 0.699
2023-10-22 21:59:01,775 (Training) Epoch: 3. Total loss: 1.692. Value loss: 0.183. Policy accuracy: 0.703
2023-10-22 21:59:28,348 (Training) Epoch: 4. Total loss: 1.687. Value loss: 0.179. Policy accuracy: 0.704
2023-10-22 21:59:55,480 (Training) Epoch: 5. Total loss: 1.682. Value loss: 0.176. Policy accuracy: 0.707
2023-10-22 22:00:22,331 (Training) Epoch: 6. Total loss: 1.674. Value loss: 0.175. Policy accuracy: 0.716
2023-10-22 22:00:49,443 (Training) Epoch: 7. Total loss: 1.677. Value loss: 0.173. Policy accuracy: 0.710
2023-10-22 22:01:16,596 (Training) Epoch: 8. Total loss: 1.675. Value loss: 0.173. Policy accuracy: 0.712
2023-10-22 22:01:43,775 (Training) Epoch: 9. Total loss: 1.665. Value loss: 0.169. Policy accuracy: 0.716
2023-10-22 22:02:11,118 (Training) Epoch: 10. Total loss: 1.663. Value loss: 0.168. Policy accuracy: 0.718
2023-10-22 22:14:45,073 (Evaluation) Win rate: 0.2
2023-10-22 22:14:45,073 (Evaluation) Model 1 wins: 27. Draws: 5. Model 2 wins: 8
2023-10-22 22:14:45,084 (Evaluation) Rejecting new model...
2023-10-22 22:14:45,112 

2023-10-22 22:14:45,113 Iteration 21
2023-10-22 22:57:13,747 (Self-play) Number of new training examples: 7416
2023-10-22 22:57:13,747 (Self-play) Number of total training examples: 129974
2023-10-22 22:57:13,747 (Self-play) Model 1 wins: 0. Draws: 59. Model 2 wins: 41
2023-10-22 22:57:42,362 (Training) Epoch: 1. Total loss: 1.721. Value loss: 0.204. Policy accuracy: 0.693
2023-10-22 22:58:10,942 (Training) Epoch: 2. Total loss: 1.703. Value loss: 0.186. Policy accuracy: 0.694
2023-10-22 22:58:39,251 (Training) Epoch: 3. Total loss: 1.691. Value loss: 0.178. Policy accuracy: 0.698
2023-10-22 22:59:08,278 (Training) Epoch: 4. Total loss: 1.684. Value loss: 0.175. Policy accuracy: 0.702
2023-10-22 22:59:37,639 (Training) Epoch: 5. Total loss: 1.677. Value loss: 0.170. Policy accuracy: 0.705
2023-10-22 23:00:07,950 (Training) Epoch: 6. Total loss: 1.676. Value loss: 0.170. Policy accuracy: 0.705
2023-10-22 23:00:39,267 (Training) Epoch: 7. Total loss: 1.671. Value loss: 0.167. Policy accuracy: 0.707
2023-10-22 23:01:09,387 (Training) Epoch: 8. Total loss: 1.665. Value loss: 0.165. Policy accuracy: 0.711
2023-10-22 23:01:39,084 (Training) Epoch: 9. Total loss: 1.665. Value loss: 0.165. Policy accuracy: 0.712
2023-10-22 23:02:09,002 (Training) Epoch: 10. Total loss: 1.656. Value loss: 0.161. Policy accuracy: 0.718
2023-10-22 23:17:40,502 (Evaluation) Win rate: 0.325
2023-10-22 23:17:40,502 (Evaluation) Model 1 wins: 24. Draws: 3. Model 2 wins: 13
2023-10-22 23:17:40,513 (Evaluation) Rejecting new model...
2023-10-22 23:17:40,537 

2023-10-22 23:17:40,538 Iteration 22
2023-10-22 23:59:33,856 (Self-play) Number of new training examples: 6996
2023-10-22 23:59:33,856 (Self-play) Number of total training examples: 136970
2023-10-22 23:59:33,856 (Self-play) Model 1 wins: 0. Draws: 55. Model 2 wins: 45
2023-10-23 00:00:04,362 (Training) Epoch: 1. Total loss: 1.718. Value loss: 0.197. Policy accuracy: 0.689
2023-10-23 00:00:34,744 (Training) Epoch: 2. Total loss: 1.695. Value loss: 0.178. Policy accuracy: 0.694
2023-10-23 00:01:05,167 (Training) Epoch: 3. Total loss: 1.690. Value loss: 0.174. Policy accuracy: 0.693
2023-10-23 00:01:35,622 (Training) Epoch: 4. Total loss: 1.679. Value loss: 0.168. Policy accuracy: 0.701
2023-10-23 00:02:05,986 (Training) Epoch: 5. Total loss: 1.672. Value loss: 0.164. Policy accuracy: 0.703
2023-10-23 00:02:36,277 (Training) Epoch: 6. Total loss: 1.671. Value loss: 0.163. Policy accuracy: 0.702
2023-10-23 00:03:06,750 (Training) Epoch: 7. Total loss: 1.667. Value loss: 0.163. Policy accuracy: 0.706
2023-10-23 00:03:37,108 (Training) Epoch: 8. Total loss: 1.659. Value loss: 0.160. Policy accuracy: 0.712
2023-10-23 00:04:07,843 (Training) Epoch: 9. Total loss: 1.656. Value loss: 0.158. Policy accuracy: 0.714
2023-10-23 00:04:38,439 (Training) Epoch: 10. Total loss: 1.655. Value loss: 0.159. Policy accuracy: 0.715
2023-10-23 00:18:42,581 (Evaluation) Win rate: 0.15
2023-10-23 00:18:42,581 (Evaluation) Model 1 wins: 21. Draws: 13. Model 2 wins: 6
2023-10-23 00:18:42,592 (Evaluation) Rejecting new model...
2023-10-23 00:18:42,622 

2023-10-23 00:18:42,622 Iteration 23
2023-10-23 00:58:48,393 (Self-play) Number of new training examples: 6822
2023-10-23 00:58:48,393 (Self-play) Number of total training examples: 143792
2023-10-23 00:58:48,393 (Self-play) Model 1 wins: 0. Draws: 49. Model 2 wins: 51
2023-10-23 00:59:19,994 (Training) Epoch: 1. Total loss: 1.747. Value loss: 0.226. Policy accuracy: 0.688
2023-10-23 00:59:51,583 (Training) Epoch: 2. Total loss: 1.724. Value loss: 0.204. Policy accuracy: 0.689
2023-10-23 01:00:23,005 (Training) Epoch: 3. Total loss: 1.710. Value loss: 0.196. Policy accuracy: 0.695
2023-10-23 01:00:54,640 (Training) Epoch: 4. Total loss: 1.696. Value loss: 0.186. Policy accuracy: 0.699
2023-10-23 01:01:26,361 (Training) Epoch: 5. Total loss: 1.690. Value loss: 0.182. Policy accuracy: 0.701
2023-10-23 01:01:58,181 (Training) Epoch: 6. Total loss: 1.684. Value loss: 0.179. Policy accuracy: 0.705
2023-10-23 01:02:29,932 (Training) Epoch: 7. Total loss: 1.685. Value loss: 0.180. Policy accuracy: 0.704
2023-10-23 01:03:01,579 (Training) Epoch: 8. Total loss: 1.676. Value loss: 0.174. Policy accuracy: 0.708
2023-10-23 01:03:33,089 (Training) Epoch: 9. Total loss: 1.673. Value loss: 0.174. Policy accuracy: 0.710
2023-10-23 01:04:04,942 (Training) Epoch: 10. Total loss: 1.667. Value loss: 0.171. Policy accuracy: 0.715
2023-10-23 01:19:47,896 (Evaluation) Win rate: 0.525
2023-10-23 01:19:47,896 (Evaluation) Model 1 wins: 11. Draws: 8. Model 2 wins: 21
2023-10-23 01:19:47,907 (Evaluation) Rejecting new model...
2023-10-23 01:19:47,929 

2023-10-23 01:19:47,930 Iteration 24
2023-10-23 02:00:07,636 (Self-play) Number of new training examples: 7038
2023-10-23 02:00:07,636 (Self-play) Number of total training examples: 150830
2023-10-23 02:00:07,636 (Self-play) Model 1 wins: 0. Draws: 51. Model 2 wins: 49
2023-10-23 02:00:41,058 (Training) Epoch: 1. Total loss: 1.775. Value loss: 0.253. Policy accuracy: 0.685
2023-10-23 02:01:14,367 (Training) Epoch: 2. Total loss: 1.737. Value loss: 0.219. Policy accuracy: 0.690
2023-10-23 02:01:47,603 (Training) Epoch: 3. Total loss: 1.722. Value loss: 0.205. Policy accuracy: 0.690
2023-10-23 02:02:20,568 (Training) Epoch: 4. Total loss: 1.712. Value loss: 0.200. Policy accuracy: 0.695
2023-10-23 02:02:53,895 (Training) Epoch: 5. Total loss: 1.702. Value loss: 0.194. Policy accuracy: 0.700
2023-10-23 02:03:26,795 (Training) Epoch: 6. Total loss: 1.697. Value loss: 0.189. Policy accuracy: 0.701
2023-10-23 02:03:59,918 (Training) Epoch: 7. Total loss: 1.692. Value loss: 0.188. Policy accuracy: 0.706
2023-10-23 02:04:33,348 (Training) Epoch: 8. Total loss: 1.687. Value loss: 0.185. Policy accuracy: 0.707
2023-10-23 02:05:07,054 (Training) Epoch: 9. Total loss: 1.680. Value loss: 0.183. Policy accuracy: 0.713
2023-10-23 02:05:40,516 (Training) Epoch: 10. Total loss: 1.675. Value loss: 0.180. Policy accuracy: 0.716
2023-10-23 02:23:14,232 (Evaluation) Win rate: 0.35
2023-10-23 02:23:14,233 (Evaluation) Model 1 wins: 17. Draws: 9. Model 2 wins: 14
2023-10-23 02:23:14,247 (Evaluation) Rejecting new model...
2023-10-23 02:23:14,270 

2023-10-23 02:23:14,271 Iteration 25
2023-10-23 03:03:32,763 (Self-play) Number of new training examples: 7132
2023-10-23 03:03:32,763 (Self-play) Number of total training examples: 157962
2023-10-23 03:03:32,763 (Self-play) Model 1 wins: 0. Draws: 55. Model 2 wins: 45
2023-10-23 03:04:07,542 (Training) Epoch: 1. Total loss: 1.768. Value loss: 0.244. Policy accuracy: 0.684
2023-10-23 03:04:41,928 (Training) Epoch: 2. Total loss: 1.733. Value loss: 0.214. Policy accuracy: 0.688
2023-10-23 03:05:16,526 (Training) Epoch: 3. Total loss: 1.717. Value loss: 0.204. Policy accuracy: 0.693
2023-10-23 03:05:51,349 (Training) Epoch: 4. Total loss: 1.707. Value loss: 0.195. Policy accuracy: 0.696
2023-10-23 03:06:26,267 (Training) Epoch: 5. Total loss: 1.697. Value loss: 0.189. Policy accuracy: 0.700
2023-10-23 03:07:01,005 (Training) Epoch: 6. Total loss: 1.692. Value loss: 0.186. Policy accuracy: 0.700
2023-10-23 03:07:35,957 (Training) Epoch: 7. Total loss: 1.681. Value loss: 0.181. Policy accuracy: 0.707
2023-10-23 03:08:10,844 (Training) Epoch: 8. Total loss: 1.678. Value loss: 0.180. Policy accuracy: 0.710
2023-10-23 03:08:45,903 (Training) Epoch: 9. Total loss: 1.676. Value loss: 0.178. Policy accuracy: 0.711
2023-10-23 03:09:20,816 (Training) Epoch: 10. Total loss: 1.672. Value loss: 0.177. Policy accuracy: 0.714
2023-10-23 03:25:55,747 (Evaluation) Win rate: 0.45
2023-10-23 03:25:55,748 (Evaluation) Model 1 wins: 17. Draws: 5. Model 2 wins: 18
2023-10-23 03:25:55,759 (Evaluation) Rejecting new model...
2023-10-23 03:25:55,781 

2023-10-23 03:25:55,782 Iteration 26
2023-10-23 04:05:33,577 (Self-play) Number of new training examples: 7076
2023-10-23 04:05:33,578 (Self-play) Number of total training examples: 165038
2023-10-23 04:05:33,578 (Self-play) Model 1 wins: 0. Draws: 57. Model 2 wins: 43
2023-10-23 04:06:09,564 (Training) Epoch: 1. Total loss: 1.805. Value loss: 0.281. Policy accuracy: 0.682
2023-10-23 04:06:46,191 (Training) Epoch: 2. Total loss: 1.764. Value loss: 0.243. Policy accuracy: 0.686
2023-10-23 04:07:22,709 (Training) Epoch: 3. Total loss: 1.740. Value loss: 0.226. Policy accuracy: 0.692
2023-10-23 04:07:58,784 (Training) Epoch: 4. Total loss: 1.732. Value loss: 0.218. Policy accuracy: 0.692
2023-10-23 04:08:35,059 (Training) Epoch: 5. Total loss: 1.718. Value loss: 0.209. Policy accuracy: 0.697
2023-10-23 04:09:11,993 (Training) Epoch: 6. Total loss: 1.711. Value loss: 0.204. Policy accuracy: 0.700
2023-10-23 04:09:48,410 (Training) Epoch: 7. Total loss: 1.700. Value loss: 0.199. Policy accuracy: 0.706
2023-10-23 04:10:24,957 (Training) Epoch: 8. Total loss: 1.697. Value loss: 0.198. Policy accuracy: 0.708
2023-10-23 04:11:01,747 (Training) Epoch: 9. Total loss: 1.690. Value loss: 0.193. Policy accuracy: 0.710
2023-10-23 04:11:38,430 (Training) Epoch: 10. Total loss: 1.688. Value loss: 0.194. Policy accuracy: 0.713
2023-10-23 04:26:29,254 (Evaluation) Win rate: 0.325
2023-10-23 04:26:29,254 (Evaluation) Model 1 wins: 17. Draws: 10. Model 2 wins: 13
2023-10-23 04:26:29,263 (Evaluation) Rejecting new model...
2023-10-23 04:26:29,289 

2023-10-23 04:26:29,290 Iteration 27
2023-10-23 05:05:41,395 (Self-play) Number of new training examples: 6890
2023-10-23 05:05:41,395 (Self-play) Number of total training examples: 171928
2023-10-23 05:05:41,395 (Self-play) Model 1 wins: 0. Draws: 53. Model 2 wins: 47
2023-10-23 05:06:19,280 (Training) Epoch: 1. Total loss: 1.826. Value loss: 0.301. Policy accuracy: 0.678
2023-10-23 05:06:56,724 (Training) Epoch: 2. Total loss: 1.779. Value loss: 0.258. Policy accuracy: 0.685
2023-10-23 05:07:34,710 (Training) Epoch: 3. Total loss: 1.753. Value loss: 0.236. Policy accuracy: 0.689
2023-10-23 05:08:12,574 (Training) Epoch: 4. Total loss: 1.739. Value loss: 0.225. Policy accuracy: 0.692
2023-10-23 05:08:50,337 (Training) Epoch: 5. Total loss: 1.726. Value loss: 0.219. Policy accuracy: 0.698
2023-10-23 05:09:28,712 (Training) Epoch: 6. Total loss: 1.716. Value loss: 0.212. Policy accuracy: 0.702
2023-10-23 05:10:07,052 (Training) Epoch: 7. Total loss: 1.708. Value loss: 0.208. Policy accuracy: 0.705
2023-10-23 05:10:44,871 (Training) Epoch: 8. Total loss: 1.707. Value loss: 0.208. Policy accuracy: 0.706
2023-10-23 05:11:23,094 (Training) Epoch: 9. Total loss: 1.700. Value loss: 0.203. Policy accuracy: 0.710
2023-10-23 05:12:01,322 (Training) Epoch: 10. Total loss: 1.692. Value loss: 0.199. Policy accuracy: 0.713
2023-10-23 05:27:11,509 (Evaluation) Win rate: 0.45
2023-10-23 05:27:11,509 (Evaluation) Model 1 wins: 13. Draws: 9. Model 2 wins: 18
2023-10-23 05:27:11,519 (Evaluation) Rejecting new model...
2023-10-23 05:27:11,541 

2023-10-23 05:27:11,542 Iteration 28
2023-10-23 06:08:33,944 (Self-play) Number of new training examples: 7514
2023-10-23 06:08:33,944 (Self-play) Number of total training examples: 179442
2023-10-23 06:08:33,945 (Self-play) Model 1 wins: 0. Draws: 63. Model 2 wins: 37
2023-10-23 06:09:13,258 (Training) Epoch: 1. Total loss: 1.818. Value loss: 0.292. Policy accuracy: 0.677
2023-10-23 06:09:52,829 (Training) Epoch: 2. Total loss: 1.772. Value loss: 0.251. Policy accuracy: 0.683
2023-10-23 06:10:32,086 (Training) Epoch: 3. Total loss: 1.750. Value loss: 0.234. Policy accuracy: 0.689
2023-10-23 06:11:11,478 (Training) Epoch: 4. Total loss: 1.731. Value loss: 0.222. Policy accuracy: 0.696
2023-10-23 06:11:50,957 (Training) Epoch: 5. Total loss: 1.720. Value loss: 0.213. Policy accuracy: 0.699
2023-10-23 06:12:30,223 (Training) Epoch: 6. Total loss: 1.709. Value loss: 0.207. Policy accuracy: 0.703
2023-10-23 06:13:09,857 (Training) Epoch: 7. Total loss: 1.701. Value loss: 0.203. Policy accuracy: 0.706
2023-10-23 06:13:49,524 (Training) Epoch: 8. Total loss: 1.696. Value loss: 0.197. Policy accuracy: 0.706
2023-10-23 06:14:28,977 (Training) Epoch: 9. Total loss: 1.691. Value loss: 0.198. Policy accuracy: 0.712
2023-10-23 06:15:08,814 (Training) Epoch: 10. Total loss: 1.686. Value loss: 0.193. Policy accuracy: 0.713
2023-10-23 06:30:20,297 (Evaluation) Win rate: 0.45
2023-10-23 06:30:20,297 (Evaluation) Model 1 wins: 17. Draws: 5. Model 2 wins: 18
2023-10-23 06:30:20,307 (Evaluation) Rejecting new model...
2023-10-23 06:30:20,329 

2023-10-23 06:30:20,330 Iteration 29
2023-10-23 07:11:01,235 (Self-play) Number of new training examples: 7032
2023-10-23 07:11:01,235 (Self-play) Number of total training examples: 186474
2023-10-23 07:11:01,235 (Self-play) Model 1 wins: 0. Draws: 49. Model 2 wins: 51
2023-10-23 07:11:41,635 (Training) Epoch: 1. Total loss: 1.813. Value loss: 0.285. Policy accuracy: 0.676
2023-10-23 07:12:22,707 (Training) Epoch: 2. Total loss: 1.767. Value loss: 0.246. Policy accuracy: 0.682
2023-10-23 07:13:03,385 (Training) Epoch: 3. Total loss: 1.742. Value loss: 0.227. Policy accuracy: 0.689
2023-10-23 07:13:44,182 (Training) Epoch: 4. Total loss: 1.727. Value loss: 0.216. Policy accuracy: 0.693
2023-10-23 07:14:25,421 (Training) Epoch: 5. Total loss: 1.718. Value loss: 0.210. Policy accuracy: 0.696
2023-10-23 07:15:06,232 (Training) Epoch: 6. Total loss: 1.707. Value loss: 0.203. Policy accuracy: 0.701
2023-10-23 07:15:47,446 (Training) Epoch: 7. Total loss: 1.700. Value loss: 0.200. Policy accuracy: 0.704
2023-10-23 07:16:28,082 (Training) Epoch: 8. Total loss: 1.693. Value loss: 0.195. Policy accuracy: 0.708
2023-10-23 07:17:09,200 (Training) Epoch: 9. Total loss: 1.688. Value loss: 0.192. Policy accuracy: 0.708
2023-10-23 07:17:50,232 (Training) Epoch: 10. Total loss: 1.683. Value loss: 0.189. Policy accuracy: 0.711
2023-10-23 07:31:56,708 (Evaluation) Win rate: 0.525
2023-10-23 07:31:56,708 (Evaluation) Model 1 wins: 16. Draws: 3. Model 2 wins: 21
2023-10-23 07:31:56,720 (Evaluation) Rejecting new model...
2023-10-23 07:31:56,743 

2023-10-23 07:31:56,744 Iteration 30
2023-10-23 08:11:46,477 (Self-play) Number of new training examples: 7170
2023-10-23 08:11:46,477 (Self-play) Number of total training examples: 193644
2023-10-23 08:11:46,477 (Self-play) Model 1 wins: 0. Draws: 56. Model 2 wins: 44
2023-10-23 08:12:28,946 (Training) Epoch: 1. Total loss: 1.804. Value loss: 0.278. Policy accuracy: 0.676
2023-10-23 08:13:11,375 (Training) Epoch: 2. Total loss: 1.761. Value loss: 0.240. Policy accuracy: 0.682
2023-10-23 08:13:53,548 (Training) Epoch: 3. Total loss: 1.737. Value loss: 0.222. Policy accuracy: 0.688
2023-10-23 08:14:35,995 (Training) Epoch: 4. Total loss: 1.723. Value loss: 0.213. Policy accuracy: 0.694
2023-10-23 08:15:18,343 (Training) Epoch: 5. Total loss: 1.711. Value loss: 0.204. Policy accuracy: 0.696
2023-10-23 08:16:00,803 (Training) Epoch: 6. Total loss: 1.703. Value loss: 0.200. Policy accuracy: 0.702
2023-10-23 08:16:43,477 (Training) Epoch: 7. Total loss: 1.696. Value loss: 0.197. Policy accuracy: 0.705
2023-10-23 08:17:26,131 (Training) Epoch: 8. Total loss: 1.689. Value loss: 0.192. Policy accuracy: 0.707
2023-10-23 08:18:08,875 (Training) Epoch: 9. Total loss: 1.686. Value loss: 0.189. Policy accuracy: 0.708
2023-10-23 08:18:51,687 (Training) Epoch: 10. Total loss: 1.679. Value loss: 0.187. Policy accuracy: 0.712
2023-10-23 08:34:53,579 (Evaluation) Win rate: 0.425
2023-10-23 08:34:53,579 (Evaluation) Model 1 wins: 9. Draws: 14. Model 2 wins: 17
2023-10-23 08:34:53,588 (Evaluation) Rejecting new model...
2023-10-23 08:34:53,612 

2023-10-23 08:34:53,613 Iteration 31
2023-10-23 09:12:25,920 (Self-play) Number of new training examples: 7534
2023-10-23 09:12:25,920 (Self-play) Number of total training examples: 201178
2023-10-23 09:12:25,920 (Self-play) Model 1 wins: 0. Draws: 68. Model 2 wins: 32
2023-10-23 09:13:10,064 (Training) Epoch: 1. Total loss: 1.796. Value loss: 0.270. Policy accuracy: 0.676
2023-10-23 09:13:54,168 (Training) Epoch: 2. Total loss: 1.756. Value loss: 0.235. Policy accuracy: 0.681
2023-10-23 09:14:38,147 (Training) Epoch: 3. Total loss: 1.733. Value loss: 0.219. Policy accuracy: 0.689
2023-10-23 09:15:22,105 (Training) Epoch: 4. Total loss: 1.719. Value loss: 0.209. Policy accuracy: 0.693
2023-10-23 09:16:06,226 (Training) Epoch: 5. Total loss: 1.706. Value loss: 0.202. Policy accuracy: 0.699
2023-10-23 09:16:50,148 (Training) Epoch: 6. Total loss: 1.697. Value loss: 0.194. Policy accuracy: 0.701
2023-10-23 09:17:34,470 (Training) Epoch: 7. Total loss: 1.691. Value loss: 0.191. Policy accuracy: 0.703
2023-10-23 09:18:18,100 (Training) Epoch: 8. Total loss: 1.680. Value loss: 0.185. Policy accuracy: 0.709
2023-10-23 09:19:02,533 (Training) Epoch: 9. Total loss: 1.678. Value loss: 0.185. Policy accuracy: 0.711
2023-10-23 09:19:46,365 (Training) Epoch: 10. Total loss: 1.676. Value loss: 0.182. Policy accuracy: 0.710
2023-10-23 09:31:49,141 (Evaluation) Win rate: 0.5
2023-10-23 09:31:49,141 (Evaluation) Model 1 wins: 16. Draws: 4. Model 2 wins: 20
2023-10-23 09:31:49,151 (Evaluation) Rejecting new model...
2023-10-23 09:31:49,173 

2023-10-23 09:31:49,174 Iteration 32
2023-10-23 10:09:55,335 (Self-play) Number of new training examples: 7282
2023-10-23 10:09:55,335 (Self-play) Number of total training examples: 208460
2023-10-23 10:09:55,335 (Self-play) Model 1 wins: 0. Draws: 58. Model 2 wins: 42
2023-10-23 10:10:41,396 (Training) Epoch: 1. Total loss: 1.787. Value loss: 0.262. Policy accuracy: 0.677
2023-10-23 10:11:26,883 (Training) Epoch: 2. Total loss: 1.753. Value loss: 0.233. Policy accuracy: 0.681
2023-10-23 10:12:12,348 (Training) Epoch: 3. Total loss: 1.729. Value loss: 0.216. Policy accuracy: 0.689
2023-10-23 10:12:58,229 (Training) Epoch: 4. Total loss: 1.713. Value loss: 0.205. Policy accuracy: 0.695
2023-10-23 10:13:44,040 (Training) Epoch: 5. Total loss: 1.702. Value loss: 0.197. Policy accuracy: 0.697
2023-10-23 10:14:29,960 (Training) Epoch: 6. Total loss: 1.693. Value loss: 0.191. Policy accuracy: 0.701
2023-10-23 10:15:15,541 (Training) Epoch: 7. Total loss: 1.685. Value loss: 0.188. Policy accuracy: 0.706
2023-10-23 10:16:01,636 (Training) Epoch: 8. Total loss: 1.679. Value loss: 0.184. Policy accuracy: 0.707
2023-10-23 10:16:47,522 (Training) Epoch: 9. Total loss: 1.673. Value loss: 0.181. Policy accuracy: 0.712
2023-10-23 10:17:33,478 (Training) Epoch: 10. Total loss: 1.670. Value loss: 0.178. Policy accuracy: 0.712
2023-10-23 10:31:27,311 (Evaluation) Win rate: 0.3
2023-10-23 10:31:27,311 (Evaluation) Model 1 wins: 18. Draws: 10. Model 2 wins: 12
2023-10-23 10:31:27,322 (Evaluation) Rejecting new model...
2023-10-23 10:31:27,349 

2023-10-23 10:31:27,350 Iteration 33
2023-10-23 11:11:07,647 (Self-play) Number of new training examples: 7400
2023-10-23 11:11:07,648 (Self-play) Number of total training examples: 215860
2023-10-23 11:11:07,648 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 11:11:54,913 (Training) Epoch: 1. Total loss: 1.782. Value loss: 0.255. Policy accuracy: 0.673
2023-10-23 11:12:41,992 (Training) Epoch: 2. Total loss: 1.743. Value loss: 0.225. Policy accuracy: 0.683
2023-10-23 11:13:28,899 (Training) Epoch: 3. Total loss: 1.723. Value loss: 0.210. Policy accuracy: 0.689
2023-10-23 11:14:16,520 (Training) Epoch: 4. Total loss: 1.709. Value loss: 0.200. Policy accuracy: 0.693
2023-10-23 11:15:03,416 (Training) Epoch: 5. Total loss: 1.698. Value loss: 0.193. Policy accuracy: 0.697
2023-10-23 11:15:50,505 (Training) Epoch: 6. Total loss: 1.688. Value loss: 0.188. Policy accuracy: 0.702
2023-10-23 11:16:37,915 (Training) Epoch: 7. Total loss: 1.682. Value loss: 0.185. Policy accuracy: 0.705
2023-10-23 11:17:25,374 (Training) Epoch: 8. Total loss: 1.673. Value loss: 0.178. Policy accuracy: 0.708
2023-10-23 11:18:12,691 (Training) Epoch: 9. Total loss: 1.670. Value loss: 0.178. Policy accuracy: 0.710
2023-10-23 11:19:00,366 (Training) Epoch: 10. Total loss: 1.663. Value loss: 0.174. Policy accuracy: 0.714
2023-10-23 11:32:21,877 (Evaluation) Win rate: 0.525
2023-10-23 11:32:21,877 (Evaluation) Model 1 wins: 16. Draws: 3. Model 2 wins: 21
2023-10-23 11:32:21,888 (Evaluation) Rejecting new model...
2023-10-23 11:32:21,913 

2023-10-23 11:32:21,914 Iteration 34
2023-10-23 12:14:45,879 (Self-play) Number of new training examples: 7456
2023-10-23 12:14:45,880 (Self-play) Number of total training examples: 223316
2023-10-23 12:14:45,880 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 12:15:34,872 (Training) Epoch: 1. Total loss: 1.776. Value loss: 0.250. Policy accuracy: 0.675
2023-10-23 12:16:23,804 (Training) Epoch: 2. Total loss: 1.738. Value loss: 0.220. Policy accuracy: 0.683
2023-10-23 12:17:13,530 (Training) Epoch: 3. Total loss: 1.719. Value loss: 0.205. Policy accuracy: 0.687
2023-10-23 12:18:03,763 (Training) Epoch: 4. Total loss: 1.708. Value loss: 0.198. Policy accuracy: 0.691
2023-10-23 12:18:54,495 (Training) Epoch: 5. Total loss: 1.695. Value loss: 0.190. Policy accuracy: 0.697
2023-10-23 12:19:43,997 (Training) Epoch: 6. Total loss: 1.683. Value loss: 0.183. Policy accuracy: 0.702
2023-10-23 12:20:33,354 (Training) Epoch: 7. Total loss: 1.680. Value loss: 0.181. Policy accuracy: 0.703
2023-10-23 12:21:22,531 (Training) Epoch: 8. Total loss: 1.672. Value loss: 0.177. Policy accuracy: 0.708
2023-10-23 12:22:11,656 (Training) Epoch: 9. Total loss: 1.666. Value loss: 0.173. Policy accuracy: 0.710
2023-10-23 12:23:01,504 (Training) Epoch: 10. Total loss: 1.660. Value loss: 0.171. Policy accuracy: 0.713
2023-10-23 12:36:17,847 (Evaluation) Win rate: 0.525
2023-10-23 12:36:17,848 (Evaluation) Model 1 wins: 8. Draws: 11. Model 2 wins: 21
2023-10-23 12:36:17,859 (Evaluation) Rejecting new model...
2023-10-23 12:36:17,881 

2023-10-23 12:36:17,883 Iteration 35
2023-10-23 13:13:50,917 (Self-play) Number of new training examples: 7040
2023-10-23 13:13:50,918 (Self-play) Number of total training examples: 230356
2023-10-23 13:13:50,918 (Self-play) Model 1 wins: 0. Draws: 59. Model 2 wins: 41
2023-10-23 13:14:42,211 (Training) Epoch: 1. Total loss: 1.767. Value loss: 0.241. Policy accuracy: 0.674
2023-10-23 13:15:33,165 (Training) Epoch: 2. Total loss: 1.735. Value loss: 0.216. Policy accuracy: 0.682
2023-10-23 13:16:23,659 (Training) Epoch: 3. Total loss: 1.715. Value loss: 0.201. Policy accuracy: 0.687
2023-10-23 13:17:14,644 (Training) Epoch: 4. Total loss: 1.703. Value loss: 0.194. Policy accuracy: 0.693
2023-10-23 13:18:05,876 (Training) Epoch: 5. Total loss: 1.689. Value loss: 0.185. Policy accuracy: 0.698
2023-10-23 13:18:56,995 (Training) Epoch: 6. Total loss: 1.680. Value loss: 0.181. Policy accuracy: 0.703
2023-10-23 13:19:47,879 (Training) Epoch: 7. Total loss: 1.673. Value loss: 0.178. Policy accuracy: 0.707
2023-10-23 13:20:38,604 (Training) Epoch: 8. Total loss: 1.667. Value loss: 0.173. Policy accuracy: 0.708
2023-10-23 13:21:29,715 (Training) Epoch: 9. Total loss: 1.658. Value loss: 0.169. Policy accuracy: 0.713
2023-10-23 13:22:20,765 (Training) Epoch: 10. Total loss: 1.656. Value loss: 0.167. Policy accuracy: 0.713
2023-10-23 13:34:44,652 (Evaluation) Win rate: 0.55
2023-10-23 13:34:44,652 (Evaluation) Model 1 wins: 13. Draws: 5. Model 2 wins: 22
2023-10-23 13:34:44,662 (Evaluation) Accepting new model...
2023-10-23 13:34:44,686 

2023-10-23 13:34:44,687 Iteration 36
2023-10-23 14:13:10,591 (Self-play) Number of new training examples: 7146
2023-10-23 14:13:10,591 (Self-play) Number of total training examples: 237502
2023-10-23 14:13:10,591 (Self-play) Model 1 wins: 0. Draws: 64. Model 2 wins: 36
2023-10-23 14:14:02,856 (Training) Epoch: 1. Total loss: 1.650. Value loss: 0.163. Policy accuracy: 0.716
2023-10-23 14:14:54,895 (Training) Epoch: 2. Total loss: 1.644. Value loss: 0.160. Policy accuracy: 0.718
2023-10-23 14:15:47,151 (Training) Epoch: 3. Total loss: 1.642. Value loss: 0.160. Policy accuracy: 0.721
2023-10-23 14:16:39,349 (Training) Epoch: 4. Total loss: 1.638. Value loss: 0.158. Policy accuracy: 0.723
2023-10-23 14:17:32,198 (Training) Epoch: 5. Total loss: 1.635. Value loss: 0.156. Policy accuracy: 0.724
2023-10-23 14:18:24,541 (Training) Epoch: 6. Total loss: 1.631. Value loss: 0.156. Policy accuracy: 0.729
2023-10-23 14:19:16,691 (Training) Epoch: 7. Total loss: 1.628. Value loss: 0.154. Policy accuracy: 0.729
2023-10-23 14:20:09,287 (Training) Epoch: 8. Total loss: 1.627. Value loss: 0.153. Policy accuracy: 0.731
2023-10-23 14:21:01,762 (Training) Epoch: 9. Total loss: 1.625. Value loss: 0.153. Policy accuracy: 0.731
2023-10-23 14:21:54,322 (Training) Epoch: 10. Total loss: 1.621. Value loss: 0.151. Policy accuracy: 0.734
2023-10-23 14:33:48,754 (Evaluation) Win rate: 0.225
2023-10-23 14:33:48,754 (Evaluation) Model 1 wins: 25. Draws: 6. Model 2 wins: 9
2023-10-23 14:33:48,764 (Evaluation) Rejecting new model...
2023-10-23 14:33:48,788 

2023-10-23 14:33:48,791 Iteration 37
2023-10-23 15:11:58,550 (Self-play) Number of new training examples: 6846
2023-10-23 15:11:58,550 (Self-play) Number of total training examples: 244348
2023-10-23 15:11:58,550 (Self-play) Model 1 wins: 0. Draws: 55. Model 2 wins: 45
2023-10-23 15:12:52,713 (Training) Epoch: 1. Total loss: 1.649. Value loss: 0.161. Policy accuracy: 0.715
2023-10-23 15:13:46,487 (Training) Epoch: 2. Total loss: 1.643. Value loss: 0.158. Policy accuracy: 0.717
2023-10-23 15:14:40,111 (Training) Epoch: 3. Total loss: 1.640. Value loss: 0.157. Policy accuracy: 0.720
2023-10-23 15:15:34,133 (Training) Epoch: 4. Total loss: 1.639. Value loss: 0.156. Policy accuracy: 0.720
2023-10-23 15:16:28,212 (Training) Epoch: 5. Total loss: 1.632. Value loss: 0.153. Policy accuracy: 0.724
2023-10-23 15:17:22,603 (Training) Epoch: 6. Total loss: 1.628. Value loss: 0.152. Policy accuracy: 0.726
2023-10-23 15:18:16,497 (Training) Epoch: 7. Total loss: 1.628. Value loss: 0.152. Policy accuracy: 0.727
2023-10-23 15:19:10,583 (Training) Epoch: 8. Total loss: 1.624. Value loss: 0.149. Policy accuracy: 0.729
2023-10-23 15:20:04,513 (Training) Epoch: 9. Total loss: 1.622. Value loss: 0.150. Policy accuracy: 0.730
2023-10-23 15:20:58,905 (Training) Epoch: 10. Total loss: 1.619. Value loss: 0.148. Policy accuracy: 0.733
2023-10-23 15:32:52,802 (Evaluation) Win rate: 0.3
2023-10-23 15:32:52,802 (Evaluation) Model 1 wins: 25. Draws: 3. Model 2 wins: 12
2023-10-23 15:32:52,813 (Evaluation) Rejecting new model...
2023-10-23 15:32:52,839 

2023-10-23 15:32:52,840 Iteration 38
2023-10-23 16:07:34,692 (Self-play) Number of new training examples: 7330
2023-10-23 16:07:34,692 (Self-play) Number of total training examples: 251678
2023-10-23 16:07:34,692 (Self-play) Model 1 wins: 0. Draws: 72. Model 2 wins: 28
2023-10-23 16:08:30,106 (Training) Epoch: 1. Total loss: 1.647. Value loss: 0.159. Policy accuracy: 0.714
2023-10-23 16:09:25,094 (Training) Epoch: 2. Total loss: 1.644. Value loss: 0.156. Policy accuracy: 0.714
2023-10-23 16:10:20,439 (Training) Epoch: 3. Total loss: 1.641. Value loss: 0.155. Policy accuracy: 0.716
2023-10-23 16:11:16,165 (Training) Epoch: 4. Total loss: 1.632. Value loss: 0.152. Policy accuracy: 0.721
2023-10-23 16:12:11,716 (Training) Epoch: 5. Total loss: 1.629. Value loss: 0.151. Policy accuracy: 0.725
2023-10-23 16:13:07,571 (Training) Epoch: 6. Total loss: 1.624. Value loss: 0.148. Policy accuracy: 0.727
2023-10-23 16:14:03,568 (Training) Epoch: 7. Total loss: 1.622. Value loss: 0.147. Policy accuracy: 0.727
2023-10-23 16:14:59,447 (Training) Epoch: 8. Total loss: 1.620. Value loss: 0.147. Policy accuracy: 0.730
2023-10-23 16:15:55,167 (Training) Epoch: 9. Total loss: 1.620. Value loss: 0.147. Policy accuracy: 0.730
2023-10-23 16:16:50,982 (Training) Epoch: 10. Total loss: 1.615. Value loss: 0.145. Policy accuracy: 0.733
2023-10-23 16:29:55,147 (Evaluation) Win rate: 0.325
2023-10-23 16:29:55,147 (Evaluation) Model 1 wins: 12. Draws: 15. Model 2 wins: 13
2023-10-23 16:29:55,160 (Evaluation) Rejecting new model...
2023-10-23 16:29:55,186 

2023-10-23 16:29:55,187 Iteration 39
2023-10-23 17:08:42,752 (Self-play) Number of new training examples: 6974
2023-10-23 17:08:42,752 (Self-play) Number of total training examples: 258652
2023-10-23 17:08:42,752 (Self-play) Model 1 wins: 0. Draws: 55. Model 2 wins: 45
2023-10-23 17:09:39,604 (Training) Epoch: 1. Total loss: 1.651. Value loss: 0.159. Policy accuracy: 0.710
2023-10-23 17:10:36,265 (Training) Epoch: 2. Total loss: 1.642. Value loss: 0.153. Policy accuracy: 0.714
2023-10-23 17:11:33,267 (Training) Epoch: 3. Total loss: 1.637. Value loss: 0.152. Policy accuracy: 0.717
2023-10-23 17:12:30,263 (Training) Epoch: 4. Total loss: 1.633. Value loss: 0.150. Policy accuracy: 0.719
2023-10-23 17:13:27,720 (Training) Epoch: 5. Total loss: 1.627. Value loss: 0.148. Policy accuracy: 0.723
2023-10-23 17:14:25,203 (Training) Epoch: 6. Total loss: 1.625. Value loss: 0.146. Policy accuracy: 0.723
2023-10-23 17:15:22,440 (Training) Epoch: 7. Total loss: 1.623. Value loss: 0.147. Policy accuracy: 0.726
2023-10-23 17:16:19,914 (Training) Epoch: 8. Total loss: 1.617. Value loss: 0.143. Policy accuracy: 0.728
2023-10-23 17:17:17,458 (Training) Epoch: 9. Total loss: 1.616. Value loss: 0.143. Policy accuracy: 0.731
2023-10-23 17:18:14,567 (Training) Epoch: 10. Total loss: 1.616. Value loss: 0.144. Policy accuracy: 0.731
2023-10-23 17:27:18,348 (Evaluation) Win rate: 0.25
2023-10-23 17:27:18,348 (Evaluation) Model 1 wins: 26. Draws: 4. Model 2 wins: 10
2023-10-23 17:27:18,358 (Evaluation) Rejecting new model...
2023-10-23 17:27:18,388 

2023-10-23 17:27:18,388 Iteration 40
2023-10-23 18:03:21,896 (Self-play) Number of new training examples: 6934
2023-10-23 18:03:21,897 (Self-play) Number of total training examples: 265586
2023-10-23 18:03:21,897 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 18:04:20,468 (Training) Epoch: 1. Total loss: 1.645. Value loss: 0.155. Policy accuracy: 0.711
2023-10-23 18:05:18,938 (Training) Epoch: 2. Total loss: 1.640. Value loss: 0.152. Policy accuracy: 0.715
2023-10-23 18:06:17,720 (Training) Epoch: 3. Total loss: 1.635. Value loss: 0.149. Policy accuracy: 0.715
2023-10-23 18:07:16,383 (Training) Epoch: 4. Total loss: 1.628. Value loss: 0.146. Policy accuracy: 0.720
2023-10-23 18:08:15,397 (Training) Epoch: 5. Total loss: 1.626. Value loss: 0.146. Policy accuracy: 0.721
2023-10-23 18:09:14,142 (Training) Epoch: 6. Total loss: 1.621. Value loss: 0.144. Policy accuracy: 0.724
2023-10-23 18:10:12,864 (Training) Epoch: 7. Total loss: 1.621. Value loss: 0.144. Policy accuracy: 0.726
2023-10-23 18:11:12,102 (Training) Epoch: 8. Total loss: 1.617. Value loss: 0.142. Policy accuracy: 0.727
2023-10-23 18:12:10,943 (Training) Epoch: 9. Total loss: 1.613. Value loss: 0.141. Policy accuracy: 0.731
2023-10-23 18:13:09,630 (Training) Epoch: 10. Total loss: 1.613. Value loss: 0.141. Policy accuracy: 0.731
2023-10-23 18:23:57,710 (Evaluation) Win rate: 0.2
2023-10-23 18:23:57,710 (Evaluation) Model 1 wins: 19. Draws: 13. Model 2 wins: 8
2023-10-23 18:23:57,722 (Evaluation) Rejecting new model...
2023-10-23 18:23:57,748 

2023-10-23 18:23:57,748 Iteration 41
2023-10-23 19:01:45,193 (Self-play) Number of new training examples: 7314
2023-10-23 19:01:45,193 (Self-play) Number of total training examples: 272900
2023-10-23 19:01:45,193 (Self-play) Model 1 wins: 0. Draws: 70. Model 2 wins: 30
2023-10-23 19:02:45,473 (Training) Epoch: 1. Total loss: 1.643. Value loss: 0.152. Policy accuracy: 0.711
2023-10-23 19:03:45,702 (Training) Epoch: 2. Total loss: 1.636. Value loss: 0.149. Policy accuracy: 0.714
2023-10-23 19:04:46,100 (Training) Epoch: 3. Total loss: 1.632. Value loss: 0.146. Policy accuracy: 0.715
2023-10-23 19:05:46,789 (Training) Epoch: 4. Total loss: 1.628. Value loss: 0.145. Policy accuracy: 0.719
2023-10-23 19:06:47,390 (Training) Epoch: 5. Total loss: 1.625. Value loss: 0.144. Policy accuracy: 0.721
2023-10-23 19:07:48,250 (Training) Epoch: 6. Total loss: 1.620. Value loss: 0.142. Policy accuracy: 0.725
2023-10-23 19:08:48,924 (Training) Epoch: 7. Total loss: 1.618. Value loss: 0.141. Policy accuracy: 0.726
2023-10-23 19:09:49,254 (Training) Epoch: 8. Total loss: 1.616. Value loss: 0.140. Policy accuracy: 0.726
2023-10-23 19:10:49,692 (Training) Epoch: 9. Total loss: 1.612. Value loss: 0.139. Policy accuracy: 0.729
2023-10-23 19:11:50,185 (Training) Epoch: 10. Total loss: 1.609. Value loss: 0.138. Policy accuracy: 0.732
2023-10-23 19:23:05,547 (Evaluation) Win rate: 0.1
2023-10-23 19:23:05,547 (Evaluation) Model 1 wins: 20. Draws: 16. Model 2 wins: 4
2023-10-23 19:23:05,556 (Evaluation) Rejecting new model...
2023-10-23 19:23:05,581 

2023-10-23 19:23:05,582 Iteration 42
2023-10-23 19:58:44,210 (Self-play) Number of new training examples: 6810
2023-10-23 19:58:44,211 (Self-play) Number of total training examples: 279710
2023-10-23 19:58:44,211 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 19:59:45,806 (Training) Epoch: 1. Total loss: 1.640. Value loss: 0.151. Policy accuracy: 0.713
2023-10-23 20:00:47,572 (Training) Epoch: 2. Total loss: 1.633. Value loss: 0.147. Policy accuracy: 0.715
2023-10-23 20:01:49,582 (Training) Epoch: 3. Total loss: 1.629. Value loss: 0.144. Policy accuracy: 0.717
2023-10-23 20:02:51,671 (Training) Epoch: 4. Total loss: 1.625. Value loss: 0.143. Policy accuracy: 0.721
2023-10-23 20:03:53,812 (Training) Epoch: 5. Total loss: 1.621. Value loss: 0.141. Policy accuracy: 0.722
2023-10-23 20:04:55,619 (Training) Epoch: 6. Total loss: 1.619. Value loss: 0.140. Policy accuracy: 0.722
2023-10-23 20:05:57,625 (Training) Epoch: 7. Total loss: 1.614. Value loss: 0.138. Policy accuracy: 0.727
2023-10-23 20:06:59,271 (Training) Epoch: 8. Total loss: 1.610. Value loss: 0.137. Policy accuracy: 0.729
2023-10-23 20:08:01,516 (Training) Epoch: 9. Total loss: 1.608. Value loss: 0.137. Policy accuracy: 0.732
2023-10-23 20:09:03,470 (Training) Epoch: 10. Total loss: 1.606. Value loss: 0.136. Policy accuracy: 0.732
2023-10-23 20:20:09,931 (Evaluation) Win rate: 0.125
2023-10-23 20:20:09,931 (Evaluation) Model 1 wins: 22. Draws: 13. Model 2 wins: 5
2023-10-23 20:20:09,941 (Evaluation) Rejecting new model...
2023-10-23 20:20:09,967 

2023-10-23 20:20:09,968 Iteration 43
2023-10-23 20:59:41,462 (Self-play) Number of new training examples: 7160
2023-10-23 20:59:41,463 (Self-play) Number of total training examples: 286870
2023-10-23 20:59:41,463 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 21:00:44,720 (Training) Epoch: 1. Total loss: 1.642. Value loss: 0.149. Policy accuracy: 0.709
2023-10-23 21:01:48,065 (Training) Epoch: 2. Total loss: 1.632. Value loss: 0.143. Policy accuracy: 0.712
2023-10-23 21:02:51,262 (Training) Epoch: 3. Total loss: 1.630. Value loss: 0.142. Policy accuracy: 0.713
2023-10-23 21:03:54,660 (Training) Epoch: 4. Total loss: 1.622. Value loss: 0.139. Policy accuracy: 0.720
2023-10-23 21:04:57,714 (Training) Epoch: 5. Total loss: 1.620. Value loss: 0.139. Policy accuracy: 0.722
2023-10-23 21:06:01,142 (Training) Epoch: 6. Total loss: 1.616. Value loss: 0.136. Policy accuracy: 0.724
2023-10-23 21:07:04,511 (Training) Epoch: 7. Total loss: 1.614. Value loss: 0.136. Policy accuracy: 0.725
2023-10-23 21:08:08,177 (Training) Epoch: 8. Total loss: 1.611. Value loss: 0.135. Policy accuracy: 0.727
2023-10-23 21:09:11,850 (Training) Epoch: 9. Total loss: 1.607. Value loss: 0.134. Policy accuracy: 0.730
2023-10-23 21:10:15,546 (Training) Epoch: 10. Total loss: 1.604. Value loss: 0.133. Policy accuracy: 0.733
2023-10-23 21:20:38,214 (Evaluation) Win rate: 0.15
2023-10-23 21:20:38,214 (Evaluation) Model 1 wins: 22. Draws: 12. Model 2 wins: 6
2023-10-23 21:20:38,224 (Evaluation) Rejecting new model...
2023-10-23 21:20:38,247 

2023-10-23 21:20:38,248 Iteration 44
2023-10-23 21:56:28,421 (Self-play) Number of new training examples: 7000
2023-10-23 21:56:28,421 (Self-play) Number of total training examples: 293870
2023-10-23 21:56:28,421 (Self-play) Model 1 wins: 0. Draws: 63. Model 2 wins: 37
2023-10-23 21:57:33,232 (Training) Epoch: 1. Total loss: 1.661. Value loss: 0.169. Policy accuracy: 0.709
2023-10-23 21:58:38,030 (Training) Epoch: 2. Total loss: 1.649. Value loss: 0.161. Policy accuracy: 0.714
2023-10-23 21:59:42,961 (Training) Epoch: 3. Total loss: 1.643. Value loss: 0.157. Policy accuracy: 0.716
2023-10-23 22:00:47,760 (Training) Epoch: 4. Total loss: 1.637. Value loss: 0.154. Policy accuracy: 0.719
2023-10-23 22:01:52,892 (Training) Epoch: 5. Total loss: 1.630. Value loss: 0.151. Policy accuracy: 0.723
2023-10-23 22:02:57,963 (Training) Epoch: 6. Total loss: 1.628. Value loss: 0.150. Policy accuracy: 0.726
2023-10-23 22:04:02,903 (Training) Epoch: 7. Total loss: 1.622. Value loss: 0.148. Policy accuracy: 0.729
2023-10-23 22:05:07,829 (Training) Epoch: 8. Total loss: 1.619. Value loss: 0.146. Policy accuracy: 0.730
2023-10-23 22:06:12,436 (Training) Epoch: 9. Total loss: 1.619. Value loss: 0.146. Policy accuracy: 0.730
2023-10-23 22:07:17,529 (Training) Epoch: 10. Total loss: 1.615. Value loss: 0.145. Policy accuracy: 0.732
2023-10-23 22:18:02,370 (Evaluation) Win rate: 0.425
2023-10-23 22:18:02,371 (Evaluation) Model 1 wins: 18. Draws: 5. Model 2 wins: 17
2023-10-23 22:18:02,381 (Evaluation) Rejecting new model...
2023-10-23 22:18:02,403 

2023-10-23 22:18:02,405 Iteration 45
2023-10-23 22:56:56,311 (Self-play) Number of new training examples: 7168
2023-10-23 22:56:56,311 (Self-play) Number of total training examples: 301038
2023-10-23 22:56:56,311 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-23 22:58:02,701 (Training) Epoch: 1. Total loss: 1.658. Value loss: 0.166. Policy accuracy: 0.709
2023-10-23 22:59:08,458 (Training) Epoch: 2. Total loss: 1.648. Value loss: 0.158. Policy accuracy: 0.712
2023-10-23 23:00:14,783 (Training) Epoch: 3. Total loss: 1.640. Value loss: 0.155. Policy accuracy: 0.717
2023-10-23 23:01:21,228 (Training) Epoch: 4. Total loss: 1.635. Value loss: 0.152. Policy accuracy: 0.717
2023-10-23 23:02:27,522 (Training) Epoch: 5. Total loss: 1.631. Value loss: 0.150. Policy accuracy: 0.722
2023-10-23 23:03:34,172 (Training) Epoch: 6. Total loss: 1.626. Value loss: 0.148. Policy accuracy: 0.725
2023-10-23 23:04:40,853 (Training) Epoch: 7. Total loss: 1.622. Value loss: 0.145. Policy accuracy: 0.726
2023-10-23 23:05:47,553 (Training) Epoch: 8. Total loss: 1.620. Value loss: 0.145. Policy accuracy: 0.728
2023-10-23 23:06:54,264 (Training) Epoch: 9. Total loss: 1.616. Value loss: 0.143. Policy accuracy: 0.729
2023-10-23 23:08:01,115 (Training) Epoch: 10. Total loss: 1.614. Value loss: 0.141. Policy accuracy: 0.731
2023-10-23 23:20:06,222 (Evaluation) Win rate: 0.4
2023-10-23 23:20:06,222 (Evaluation) Model 1 wins: 18. Draws: 6. Model 2 wins: 16
2023-10-23 23:20:06,232 (Evaluation) Rejecting new model...
2023-10-23 23:20:06,255 

2023-10-23 23:20:06,256 Iteration 46
2023-10-24 00:01:02,331 (Self-play) Number of new training examples: 7532
2023-10-24 00:01:02,332 (Self-play) Number of total training examples: 308570
2023-10-24 00:01:02,332 (Self-play) Model 1 wins: 0. Draws: 68. Model 2 wins: 32
2023-10-24 00:02:14,999 (Training) Epoch: 1. Total loss: 1.656. Value loss: 0.165. Policy accuracy: 0.710
2023-10-24 00:03:29,952 (Training) Epoch: 2. Total loss: 1.645. Value loss: 0.155. Policy accuracy: 0.713
2023-10-24 00:04:46,228 (Training) Epoch: 3. Total loss: 1.640. Value loss: 0.153. Policy accuracy: 0.714
2023-10-24 00:06:02,677 (Training) Epoch: 4. Total loss: 1.633. Value loss: 0.150. Policy accuracy: 0.719
2023-10-24 00:07:17,868 (Training) Epoch: 5. Total loss: 1.630. Value loss: 0.148. Policy accuracy: 0.720
2023-10-24 00:08:30,419 (Training) Epoch: 6. Total loss: 1.625. Value loss: 0.145. Policy accuracy: 0.722
2023-10-24 00:09:44,805 (Training) Epoch: 7. Total loss: 1.621. Value loss: 0.143. Policy accuracy: 0.725
2023-10-24 00:10:58,961 (Training) Epoch: 8. Total loss: 1.617. Value loss: 0.142. Policy accuracy: 0.728
2023-10-24 00:12:13,112 (Training) Epoch: 9. Total loss: 1.615. Value loss: 0.141. Policy accuracy: 0.730
2023-10-24 00:13:24,542 (Training) Epoch: 10. Total loss: 1.611. Value loss: 0.140. Policy accuracy: 0.733
2023-10-24 00:23:03,504 (Evaluation) Win rate: 0.225
2023-10-24 00:23:03,504 (Evaluation) Model 1 wins: 24. Draws: 7. Model 2 wins: 9
2023-10-24 00:23:03,517 (Evaluation) Rejecting new model...
2023-10-24 00:23:03,542 

2023-10-24 00:23:03,543 Iteration 47
2023-10-24 01:00:24,586 (Self-play) Number of new training examples: 6836
2023-10-24 01:00:24,586 (Self-play) Number of total training examples: 315406
2023-10-24 01:00:24,586 (Self-play) Model 1 wins: 0. Draws: 53. Model 2 wins: 47
2023-10-24 01:01:33,929 (Training) Epoch: 1. Total loss: 1.654. Value loss: 0.162. Policy accuracy: 0.710
2023-10-24 01:02:43,637 (Training) Epoch: 2. Total loss: 1.644. Value loss: 0.154. Policy accuracy: 0.712
2023-10-24 01:03:52,961 (Training) Epoch: 3. Total loss: 1.635. Value loss: 0.149. Policy accuracy: 0.716
2023-10-24 01:05:02,686 (Training) Epoch: 4. Total loss: 1.632. Value loss: 0.147. Policy accuracy: 0.718
2023-10-24 01:06:11,848 (Training) Epoch: 5. Total loss: 1.628. Value loss: 0.146. Policy accuracy: 0.721
2023-10-24 01:07:21,157 (Training) Epoch: 6. Total loss: 1.622. Value loss: 0.142. Policy accuracy: 0.723
2023-10-24 01:08:30,795 (Training) Epoch: 7. Total loss: 1.620. Value loss: 0.143. Policy accuracy: 0.725
2023-10-24 01:09:40,015 (Training) Epoch: 8. Total loss: 1.615. Value loss: 0.140. Policy accuracy: 0.729
2023-10-24 01:10:49,686 (Training) Epoch: 9. Total loss: 1.611. Value loss: 0.140. Policy accuracy: 0.732
2023-10-24 01:11:59,729 (Training) Epoch: 10. Total loss: 1.607. Value loss: 0.137. Policy accuracy: 0.734
2023-10-24 01:23:44,877 (Evaluation) Win rate: 0.25
2023-10-24 01:23:44,877 (Evaluation) Model 1 wins: 24. Draws: 6. Model 2 wins: 10
2023-10-24 01:23:44,887 (Evaluation) Rejecting new model...
2023-10-24 01:23:44,911 

2023-10-24 01:23:44,912 Iteration 48
2023-10-24 02:00:22,451 (Self-play) Number of new training examples: 6894
2023-10-24 02:00:22,451 (Self-play) Number of total training examples: 322300
2023-10-24 02:00:22,451 (Self-play) Model 1 wins: 0. Draws: 56. Model 2 wins: 44
2023-10-24 02:01:33,391 (Training) Epoch: 1. Total loss: 1.674. Value loss: 0.181. Policy accuracy: 0.708
2023-10-24 02:02:44,545 (Training) Epoch: 2. Total loss: 1.659. Value loss: 0.169. Policy accuracy: 0.711
2023-10-24 02:03:55,222 (Training) Epoch: 3. Total loss: 1.651. Value loss: 0.164. Policy accuracy: 0.714
2023-10-24 02:05:06,214 (Training) Epoch: 4. Total loss: 1.641. Value loss: 0.159. Policy accuracy: 0.720
2023-10-24 02:06:16,336 (Training) Epoch: 5. Total loss: 1.638. Value loss: 0.156. Policy accuracy: 0.720
2023-10-24 02:07:27,473 (Training) Epoch: 6. Total loss: 1.633. Value loss: 0.153. Policy accuracy: 0.722
2023-10-24 02:08:38,130 (Training) Epoch: 7. Total loss: 1.629. Value loss: 0.151. Policy accuracy: 0.726
2023-10-24 02:09:49,205 (Training) Epoch: 8. Total loss: 1.624. Value loss: 0.150. Policy accuracy: 0.728
2023-10-24 02:11:00,623 (Training) Epoch: 9. Total loss: 1.623. Value loss: 0.149. Policy accuracy: 0.729
2023-10-24 02:12:11,227 (Training) Epoch: 10. Total loss: 1.618. Value loss: 0.145. Policy accuracy: 0.730
2023-10-24 02:24:51,301 (Evaluation) Win rate: 0.25
2023-10-24 02:24:51,301 (Evaluation) Model 1 wins: 19. Draws: 11. Model 2 wins: 10
2023-10-24 02:24:51,310 (Evaluation) Rejecting new model...
2023-10-24 02:24:51,338 

2023-10-24 02:24:51,339 Iteration 49
2023-10-24 03:00:38,062 (Self-play) Number of new training examples: 6866
2023-10-24 03:00:38,062 (Self-play) Number of total training examples: 329166
2023-10-24 03:00:38,062 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-24 03:01:50,460 (Training) Epoch: 1. Total loss: 1.691. Value loss: 0.197. Policy accuracy: 0.707
2023-10-24 03:03:02,731 (Training) Epoch: 2. Total loss: 1.671. Value loss: 0.181. Policy accuracy: 0.712
2023-10-24 03:04:15,314 (Training) Epoch: 3. Total loss: 1.661. Value loss: 0.174. Policy accuracy: 0.716
2023-10-24 03:05:27,466 (Training) Epoch: 4. Total loss: 1.655. Value loss: 0.171. Policy accuracy: 0.719
2023-10-24 03:06:39,817 (Training) Epoch: 5. Total loss: 1.647. Value loss: 0.165. Policy accuracy: 0.720
2023-10-24 03:07:52,477 (Training) Epoch: 6. Total loss: 1.640. Value loss: 0.163. Policy accuracy: 0.725
2023-10-24 03:09:05,171 (Training) Epoch: 7. Total loss: 1.638. Value loss: 0.161. Policy accuracy: 0.725
2023-10-24 03:10:17,778 (Training) Epoch: 8. Total loss: 1.631. Value loss: 0.158. Policy accuracy: 0.729
2023-10-24 03:11:30,716 (Training) Epoch: 9. Total loss: 1.630. Value loss: 0.157. Policy accuracy: 0.730
2023-10-24 03:12:43,420 (Training) Epoch: 10. Total loss: 1.624. Value loss: 0.154. Policy accuracy: 0.732
2023-10-24 03:23:35,459 (Evaluation) Win rate: 0.1
2023-10-24 03:23:35,459 (Evaluation) Model 1 wins: 22. Draws: 14. Model 2 wins: 4
2023-10-24 03:23:35,471 (Evaluation) Rejecting new model...
2023-10-24 03:23:35,495 

2023-10-24 03:23:35,496 Iteration 50
2023-10-24 03:59:24,493 (Self-play) Number of new training examples: 6846
2023-10-24 03:59:24,494 (Self-play) Number of total training examples: 336012
2023-10-24 03:59:24,494 (Self-play) Model 1 wins: 0. Draws: 57. Model 2 wins: 43
2023-10-24 04:00:37,794 (Training) Epoch: 1. Total loss: 1.688. Value loss: 0.194. Policy accuracy: 0.708
2023-10-24 04:01:51,308 (Training) Epoch: 2. Total loss: 1.669. Value loss: 0.180. Policy accuracy: 0.713
2023-10-24 04:03:05,420 (Training) Epoch: 3. Total loss: 1.660. Value loss: 0.173. Policy accuracy: 0.715
2023-10-24 04:04:19,513 (Training) Epoch: 4. Total loss: 1.652. Value loss: 0.168. Policy accuracy: 0.719
2023-10-24 04:05:32,939 (Training) Epoch: 5. Total loss: 1.644. Value loss: 0.164. Policy accuracy: 0.722
2023-10-24 04:06:47,019 (Training) Epoch: 6. Total loss: 1.639. Value loss: 0.160. Policy accuracy: 0.724
2023-10-24 04:08:00,397 (Training) Epoch: 7. Total loss: 1.634. Value loss: 0.159. Policy accuracy: 0.727
2023-10-24 04:09:15,222 (Training) Epoch: 8. Total loss: 1.632. Value loss: 0.157. Policy accuracy: 0.728
2023-10-24 04:10:29,507 (Training) Epoch: 9. Total loss: 1.626. Value loss: 0.153. Policy accuracy: 0.730
2023-10-24 04:11:44,130 (Training) Epoch: 10. Total loss: 1.622. Value loss: 0.152. Policy accuracy: 0.734
2023-10-24 04:22:22,289 (Evaluation) Win rate: 0.125
2023-10-24 04:22:22,289 (Evaluation) Model 1 wins: 30. Draws: 5. Model 2 wins: 5
2023-10-24 04:22:22,298 (Evaluation) Rejecting new model...
2023-10-24 04:22:22,323 

2023-10-24 04:22:22,324 Iteration 51
2023-10-24 05:00:38,022 (Self-play) Number of new training examples: 7350
2023-10-24 05:00:38,023 (Self-play) Number of total training examples: 343362
2023-10-24 05:00:38,023 (Self-play) Model 1 wins: 0. Draws: 64. Model 2 wins: 36
2023-10-24 05:01:54,117 (Training) Epoch: 1. Total loss: 1.687. Value loss: 0.193. Policy accuracy: 0.708
2023-10-24 05:03:09,836 (Training) Epoch: 2. Total loss: 1.668. Value loss: 0.178. Policy accuracy: 0.712
2023-10-24 05:04:26,279 (Training) Epoch: 3. Total loss: 1.658. Value loss: 0.171. Policy accuracy: 0.714
2023-10-24 05:05:42,155 (Training) Epoch: 4. Total loss: 1.650. Value loss: 0.166. Policy accuracy: 0.718
2023-10-24 05:06:57,813 (Training) Epoch: 5. Total loss: 1.641. Value loss: 0.161. Policy accuracy: 0.723
2023-10-24 05:08:14,299 (Training) Epoch: 6. Total loss: 1.637. Value loss: 0.158. Policy accuracy: 0.724
2023-10-24 05:09:30,793 (Training) Epoch: 7. Total loss: 1.633. Value loss: 0.156. Policy accuracy: 0.726
2023-10-24 05:10:46,961 (Training) Epoch: 8. Total loss: 1.627. Value loss: 0.153. Policy accuracy: 0.729
2023-10-24 05:12:03,535 (Training) Epoch: 9. Total loss: 1.624. Value loss: 0.152. Policy accuracy: 0.731
2023-10-24 05:13:19,224 (Training) Epoch: 10. Total loss: 1.620. Value loss: 0.150. Policy accuracy: 0.733
2023-10-24 05:22:11,544 (Evaluation) Win rate: 0.55
2023-10-24 05:22:11,544 (Evaluation) Model 1 wins: 13. Draws: 5. Model 2 wins: 22
2023-10-24 05:22:11,554 (Evaluation) Accepting new model...
2023-10-24 05:22:11,578 

2023-10-24 05:22:11,580 Iteration 52
2023-10-24 05:55:49,996 (Self-play) Number of new training examples: 6692
2023-10-24 05:55:49,997 (Self-play) Number of total training examples: 350054
2023-10-24 05:55:49,997 (Self-play) Model 1 wins: 0. Draws: 56. Model 2 wins: 44
2023-10-24 05:57:07,456 (Training) Epoch: 1. Total loss: 1.615. Value loss: 0.146. Policy accuracy: 0.735
2023-10-24 05:58:25,125 (Training) Epoch: 2. Total loss: 1.612. Value loss: 0.145. Policy accuracy: 0.736
2023-10-24 05:59:42,903 (Training) Epoch: 3. Total loss: 1.610. Value loss: 0.145. Policy accuracy: 0.738
2023-10-24 06:01:00,349 (Training) Epoch: 4. Total loss: 1.608. Value loss: 0.144. Policy accuracy: 0.739
2023-10-24 06:02:18,724 (Training) Epoch: 5. Total loss: 1.605. Value loss: 0.143. Policy accuracy: 0.741
2023-10-24 06:03:36,181 (Training) Epoch: 6. Total loss: 1.603. Value loss: 0.142. Policy accuracy: 0.743
2023-10-24 06:04:53,527 (Training) Epoch: 7. Total loss: 1.601. Value loss: 0.141. Policy accuracy: 0.743
2023-10-24 06:06:11,595 (Training) Epoch: 8. Total loss: 1.600. Value loss: 0.140. Policy accuracy: 0.745
2023-10-24 06:07:29,187 (Training) Epoch: 9. Total loss: 1.598. Value loss: 0.140. Policy accuracy: 0.747
2023-10-24 06:08:46,917 (Training) Epoch: 10. Total loss: 1.596. Value loss: 0.139. Policy accuracy: 0.748
2023-10-24 06:19:10,186 (Evaluation) Win rate: 0.275
2023-10-24 06:19:10,186 (Evaluation) Model 1 wins: 26. Draws: 3. Model 2 wins: 11
2023-10-24 06:19:10,196 (Evaluation) Rejecting new model...
2023-10-24 06:19:10,220 

2023-10-24 06:19:10,222 Iteration 53
2023-10-24 06:52:22,837 (Self-play) Number of new training examples: 6526
2023-10-24 06:52:22,838 (Self-play) Number of total training examples: 356580
2023-10-24 06:52:22,838 (Self-play) Model 1 wins: 0. Draws: 54. Model 2 wins: 46
2023-10-24 06:53:40,686 (Training) Epoch: 1. Total loss: 1.630. Value loss: 0.161. Policy accuracy: 0.734
2023-10-24 06:54:58,645 (Training) Epoch: 2. Total loss: 1.625. Value loss: 0.158. Policy accuracy: 0.736
2023-10-24 06:56:16,591 (Training) Epoch: 3. Total loss: 1.622. Value loss: 0.156. Policy accuracy: 0.738
2023-10-24 06:57:34,688 (Training) Epoch: 4. Total loss: 1.619. Value loss: 0.154. Policy accuracy: 0.739
2023-10-24 06:58:52,593 (Training) Epoch: 5. Total loss: 1.615. Value loss: 0.152. Policy accuracy: 0.741
2023-10-24 07:00:10,599 (Training) Epoch: 6. Total loss: 1.612. Value loss: 0.151. Policy accuracy: 0.744
2023-10-24 07:01:28,784 (Training) Epoch: 7. Total loss: 1.610. Value loss: 0.149. Policy accuracy: 0.744
2023-10-24 07:02:47,903 (Training) Epoch: 8. Total loss: 1.609. Value loss: 0.149. Policy accuracy: 0.745
2023-10-24 07:04:05,931 (Training) Epoch: 9. Total loss: 1.606. Value loss: 0.148. Policy accuracy: 0.747
2023-10-24 07:05:23,984 (Training) Epoch: 10. Total loss: 1.602. Value loss: 0.145. Policy accuracy: 0.747
2023-10-24 07:13:33,459 (Evaluation) Win rate: 0.425
2023-10-24 07:13:33,460 (Evaluation) Model 1 wins: 18. Draws: 5. Model 2 wins: 17
2023-10-24 07:13:33,470 (Evaluation) Rejecting new model...
2023-10-24 07:13:33,494 

2023-10-24 07:13:33,494 Iteration 54
2023-10-24 07:48:29,741 (Self-play) Number of new training examples: 6932
2023-10-24 07:48:29,741 (Self-play) Number of total training examples: 363512
2023-10-24 07:48:29,741 (Self-play) Model 1 wins: 0. Draws: 58. Model 2 wins: 42
2023-10-24 07:49:49,317 (Training) Epoch: 1. Total loss: 1.629. Value loss: 0.159. Policy accuracy: 0.734
2023-10-24 07:51:08,647 (Training) Epoch: 2. Total loss: 1.623. Value loss: 0.156. Policy accuracy: 0.737
2023-10-24 07:52:27,917 (Training) Epoch: 3. Total loss: 1.619. Value loss: 0.153. Policy accuracy: 0.738
2023-10-24 07:53:47,097 (Training) Epoch: 4. Total loss: 1.616. Value loss: 0.152. Policy accuracy: 0.740
2023-10-24 07:55:07,294 (Training) Epoch: 5. Total loss: 1.615. Value loss: 0.151. Policy accuracy: 0.740
2023-10-24 07:56:26,478 (Training) Epoch: 6. Total loss: 1.611. Value loss: 0.149. Policy accuracy: 0.742
2023-10-24 07:57:45,765 (Training) Epoch: 7. Total loss: 1.607. Value loss: 0.147. Policy accuracy: 0.745
2023-10-24 07:59:05,368 (Training) Epoch: 8. Total loss: 1.605. Value loss: 0.147. Policy accuracy: 0.746
2023-10-24 08:00:25,167 (Training) Epoch: 9. Total loss: 1.606. Value loss: 0.147. Policy accuracy: 0.746
2023-10-24 08:01:45,381 (Training) Epoch: 10. Total loss: 1.600. Value loss: 0.144. Policy accuracy: 0.748
2023-10-24 08:10:18,395 (Evaluation) Win rate: 0.75
2023-10-24 08:10:18,395 (Evaluation) Model 1 wins: 7. Draws: 3. Model 2 wins: 30
2023-10-24 08:10:18,406 (Evaluation) Accepting new model...
2023-10-24 08:10:18,428 

2023-10-24 08:10:18,429 Iteration 55
2023-10-24 08:44:42,157 (Self-play) Number of new training examples: 7158
2023-10-24 08:44:42,157 (Self-play) Number of total training examples: 370670
2023-10-24 08:44:42,157 (Self-play) Model 1 wins: 0. Draws: 65. Model 2 wins: 35
2023-10-24 08:46:03,789 (Training) Epoch: 1. Total loss: 1.599. Value loss: 0.143. Policy accuracy: 0.748
2023-10-24 08:47:24,994 (Training) Epoch: 2. Total loss: 1.596. Value loss: 0.142. Policy accuracy: 0.751
2023-10-24 08:48:46,139 (Training) Epoch: 3. Total loss: 1.597. Value loss: 0.142. Policy accuracy: 0.751
2023-10-24 08:50:07,371 (Training) Epoch: 4. Total loss: 1.594. Value loss: 0.140. Policy accuracy: 0.752
2023-10-24 08:51:28,870 (Training) Epoch: 5. Total loss: 1.593. Value loss: 0.140. Policy accuracy: 0.752
2023-10-24 08:52:49,688 (Training) Epoch: 6. Total loss: 1.592. Value loss: 0.139. Policy accuracy: 0.753
2023-10-24 08:54:10,716 (Training) Epoch: 7. Total loss: 1.590. Value loss: 0.139. Policy accuracy: 0.754
2023-10-24 08:55:31,329 (Training) Epoch: 8. Total loss: 1.589. Value loss: 0.139. Policy accuracy: 0.755
2023-10-24 08:56:52,600 (Training) Epoch: 9. Total loss: 1.587. Value loss: 0.138. Policy accuracy: 0.756
2023-10-24 08:58:13,877 (Training) Epoch: 10. Total loss: 1.588. Value loss: 0.139. Policy accuracy: 0.756
2023-10-24 09:07:10,469 (Evaluation) Win rate: 0.2
2023-10-24 09:07:10,469 (Evaluation) Model 1 wins: 24. Draws: 8. Model 2 wins: 8
2023-10-24 09:07:10,484 (Evaluation) Rejecting new model...
2023-10-24 09:07:10,513 

2023-10-24 09:07:10,514 Iteration 56
2023-10-24 09:42:06,802 (Self-play) Number of new training examples: 6972
2023-10-24 09:42:06,802 (Self-play) Number of total training examples: 377642
2023-10-24 09:42:06,802 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-24 09:43:29,453 (Training) Epoch: 1. Total loss: 1.597. Value loss: 0.141. Policy accuracy: 0.749
2023-10-24 09:44:52,071 (Training) Epoch: 2. Total loss: 1.597. Value loss: 0.140. Policy accuracy: 0.748
2023-10-24 09:46:15,111 (Training) Epoch: 3. Total loss: 1.593. Value loss: 0.139. Policy accuracy: 0.751
2023-10-24 09:47:37,691 (Training) Epoch: 4. Total loss: 1.592. Value loss: 0.139. Policy accuracy: 0.753
2023-10-24 09:49:00,509 (Training) Epoch: 5. Total loss: 1.592. Value loss: 0.138. Policy accuracy: 0.752
2023-10-24 09:50:22,958 (Training) Epoch: 6. Total loss: 1.589. Value loss: 0.137. Policy accuracy: 0.753
2023-10-24 09:51:46,016 (Training) Epoch: 7. Total loss: 1.590. Value loss: 0.137. Policy accuracy: 0.753
2023-10-24 09:53:08,745 (Training) Epoch: 8. Total loss: 1.586. Value loss: 0.136. Policy accuracy: 0.756
2023-10-24 09:54:30,550 (Training) Epoch: 9. Total loss: 1.586. Value loss: 0.136. Policy accuracy: 0.756
2023-10-24 09:55:52,756 (Training) Epoch: 10. Total loss: 1.585. Value loss: 0.136. Policy accuracy: 0.757
2023-10-24 10:04:08,648 (Evaluation) Win rate: 0.4
2023-10-24 10:04:08,649 (Evaluation) Model 1 wins: 16. Draws: 8. Model 2 wins: 16
2023-10-24 10:04:08,658 (Evaluation) Rejecting new model...
2023-10-24 10:04:08,681 

2023-10-24 10:04:08,681 Iteration 57
2023-10-24 10:38:26,757 (Self-play) Number of new training examples: 6954
2023-10-24 10:38:26,757 (Self-play) Number of total training examples: 384596
2023-10-24 10:38:26,757 (Self-play) Model 1 wins: 0. Draws: 64. Model 2 wins: 36
2023-10-24 10:39:51,118 (Training) Epoch: 1. Total loss: 1.598. Value loss: 0.140. Policy accuracy: 0.747
2023-10-24 10:41:15,838 (Training) Epoch: 2. Total loss: 1.596. Value loss: 0.139. Policy accuracy: 0.748
2023-10-24 10:42:40,454 (Training) Epoch: 3. Total loss: 1.594. Value loss: 0.139. Policy accuracy: 0.749
2023-10-24 10:44:05,320 (Training) Epoch: 4. Total loss: 1.593. Value loss: 0.138. Policy accuracy: 0.751
2023-10-24 10:45:29,701 (Training) Epoch: 5. Total loss: 1.591. Value loss: 0.137. Policy accuracy: 0.752
2023-10-24 10:46:54,530 (Training) Epoch: 6. Total loss: 1.589. Value loss: 0.136. Policy accuracy: 0.752
2023-10-24 10:48:18,517 (Training) Epoch: 7. Total loss: 1.588. Value loss: 0.136. Policy accuracy: 0.754
2023-10-24 10:49:42,836 (Training) Epoch: 8. Total loss: 1.587. Value loss: 0.135. Policy accuracy: 0.755
2023-10-24 10:51:06,531 (Training) Epoch: 9. Total loss: 1.585. Value loss: 0.135. Policy accuracy: 0.756
2023-10-24 10:52:30,311 (Training) Epoch: 10. Total loss: 1.584. Value loss: 0.134. Policy accuracy: 0.758
2023-10-24 11:00:17,999 (Evaluation) Win rate: 0.125
2023-10-24 11:00:17,999 (Evaluation) Model 1 wins: 22. Draws: 13. Model 2 wins: 5
2023-10-24 11:00:18,008 (Evaluation) Rejecting new model...
2023-10-24 11:00:18,030 

2023-10-24 11:00:18,031 Iteration 58
2023-10-24 11:35:59,311 (Self-play) Number of new training examples: 6976
2023-10-24 11:35:59,311 (Self-play) Number of total training examples: 391572
2023-10-24 11:35:59,311 (Self-play) Model 1 wins: 0. Draws: 63. Model 2 wins: 37
2023-10-24 11:37:24,714 (Training) Epoch: 1. Total loss: 1.612. Value loss: 0.153. Policy accuracy: 0.747
2023-10-24 11:38:50,556 (Training) Epoch: 2. Total loss: 1.605. Value loss: 0.148. Policy accuracy: 0.748
2023-10-24 11:40:16,851 (Training) Epoch: 3. Total loss: 1.603. Value loss: 0.147. Policy accuracy: 0.749
2023-10-24 11:41:42,962 (Training) Epoch: 4. Total loss: 1.601. Value loss: 0.146. Policy accuracy: 0.751
2023-10-24 11:43:08,882 (Training) Epoch: 5. Total loss: 1.598. Value loss: 0.145. Policy accuracy: 0.753
2023-10-24 11:44:35,183 (Training) Epoch: 6. Total loss: 1.597. Value loss: 0.143. Policy accuracy: 0.753
2023-10-24 11:46:01,948 (Training) Epoch: 7. Total loss: 1.595. Value loss: 0.144. Policy accuracy: 0.755
2023-10-24 11:47:28,130 (Training) Epoch: 8. Total loss: 1.592. Value loss: 0.142. Policy accuracy: 0.756
2023-10-24 11:48:54,110 (Training) Epoch: 9. Total loss: 1.592. Value loss: 0.142. Policy accuracy: 0.755
2023-10-24 11:50:19,521 (Training) Epoch: 10. Total loss: 1.592. Value loss: 0.142. Policy accuracy: 0.756
2023-10-24 11:57:08,020 (Evaluation) Win rate: 0.275
2023-10-24 11:57:08,021 (Evaluation) Model 1 wins: 26. Draws: 3. Model 2 wins: 11
2023-10-24 11:57:08,031 (Evaluation) Rejecting new model...
2023-10-24 11:57:08,056 

2023-10-24 11:57:08,057 Iteration 59
2023-10-24 12:30:07,923 (Self-play) Number of new training examples: 6664
2023-10-24 12:30:07,923 (Self-play) Number of total training examples: 398236
2023-10-24 12:30:07,923 (Self-play) Model 1 wins: 0. Draws: 61. Model 2 wins: 39
2023-10-24 12:31:35,022 (Training) Epoch: 1. Total loss: 1.609. Value loss: 0.151. Policy accuracy: 0.748
2023-10-24 12:33:01,849 (Training) Epoch: 2. Total loss: 1.605. Value loss: 0.147. Policy accuracy: 0.748
2023-10-24 12:34:29,678 (Training) Epoch: 3. Total loss: 1.602. Value loss: 0.145. Policy accuracy: 0.748
2023-10-24 12:35:56,673 (Training) Epoch: 4. Total loss: 1.599. Value loss: 0.144. Policy accuracy: 0.750
2023-10-24 12:37:23,680 (Training) Epoch: 5. Total loss: 1.597. Value loss: 0.143. Policy accuracy: 0.751
2023-10-24 12:38:50,655 (Training) Epoch: 6. Total loss: 1.596. Value loss: 0.143. Policy accuracy: 0.752
2023-10-24 12:40:18,234 (Training) Epoch: 7. Total loss: 1.594. Value loss: 0.141. Policy accuracy: 0.754
2023-10-24 12:41:45,445 (Training) Epoch: 8. Total loss: 1.592. Value loss: 0.140. Policy accuracy: 0.753
2023-10-24 12:43:12,925 (Training) Epoch: 9. Total loss: 1.592. Value loss: 0.141. Policy accuracy: 0.755
2023-10-24 12:44:40,628 (Training) Epoch: 10. Total loss: 1.590. Value loss: 0.140. Policy accuracy: 0.756
2023-10-24 12:53:58,958 (Evaluation) Win rate: 0.05
2023-10-24 12:53:58,958 (Evaluation) Model 1 wins: 17. Draws: 21. Model 2 wins: 2
2023-10-24 12:53:58,967 (Evaluation) Rejecting new model...
2023-10-24 12:53:58,990 

2023-10-24 12:53:58,991 Iteration 60
2023-10-24 13:28:00,640 (Self-play) Number of new training examples: 6594
2023-10-24 13:28:00,640 (Self-play) Number of total training examples: 404830
2023-10-24 13:28:00,640 (Self-play) Model 1 wins: 0. Draws: 60. Model 2 wins: 40
2023-10-24 13:29:36,502 (Training) Epoch: 1. Total loss: 1.622. Value loss: 0.163. Policy accuracy: 0.746
2023-10-24 13:31:12,318 (Training) Epoch: 2. Total loss: 1.616. Value loss: 0.158. Policy accuracy: 0.748
2023-10-24 13:32:49,224 (Training) Epoch: 3. Total loss: 1.610. Value loss: 0.153. Policy accuracy: 0.749
2023-10-24 13:34:24,804 (Training) Epoch: 4. Total loss: 1.608. Value loss: 0.152. Policy accuracy: 0.750
2023-10-24 13:35:59,708 (Training) Epoch: 5. Total loss: 1.604. Value loss: 0.150. Policy accuracy: 0.752
2023-10-24 13:37:36,208 (Training) Epoch: 6. Total loss: 1.602. Value loss: 0.149. Policy accuracy: 0.752
2023-10-24 13:39:13,164 (Training) Epoch: 7. Total loss: 1.601. Value loss: 0.148. Policy accuracy: 0.753
2023-10-24 13:40:47,578 (Training) Epoch: 8. Total loss: 1.599. Value loss: 0.148. Policy accuracy: 0.755
2023-10-24 13:42:23,388 (Training) Epoch: 9. Total loss: 1.597. Value loss: 0.146. Policy accuracy: 0.756
2023-10-24 13:43:57,907 (Training) Epoch: 10. Total loss: 1.595. Value loss: 0.145. Policy accuracy: 0.756
2023-10-24 13:52:31,010 (Evaluation) Win rate: 0.125
2023-10-24 13:52:31,010 (Evaluation) Model 1 wins: 15. Draws: 20. Model 2 wins: 5
2023-10-24 13:52:31,021 (Evaluation) Rejecting new model...
2023-10-24 13:52:31,045 

2023-10-24 13:52:31,045 Iteration 61
2023-10-24 14:28:44,469 (Self-play) Number of new training examples: 7212
2023-10-24 14:28:44,469 (Self-play) Number of total training examples: 412042
2023-10-24 14:28:44,469 (Self-play) Model 1 wins: 0. Draws: 69. Model 2 wins: 31
2023-10-24 14:30:22,422 (Training) Epoch: 1. Total loss: 1.623. Value loss: 0.163. Policy accuracy: 0.745
2023-10-24 14:31:59,836 (Training) Epoch: 2. Total loss: 1.615. Value loss: 0.155. Policy accuracy: 0.746
2023-10-24 14:33:37,414 (Training) Epoch: 3. Total loss: 1.610. Value loss: 0.152. Policy accuracy: 0.747
2023-10-24 14:35:15,460 (Training) Epoch: 4. Total loss: 1.606. Value loss: 0.151. Policy accuracy: 0.750
2023-10-24 14:36:52,559 (Training) Epoch: 5. Total loss: 1.602. Value loss: 0.148. Policy accuracy: 0.751
2023-10-24 14:38:29,676 (Training) Epoch: 6. Total loss: 1.601. Value loss: 0.147. Policy accuracy: 0.751
2023-10-24 14:40:07,451 (Training) Epoch: 7. Total loss: 1.597. Value loss: 0.145. Policy accuracy: 0.754
2023-10-24 14:41:44,434 (Training) Epoch: 8. Total loss: 1.598. Value loss: 0.146. Policy accuracy: 0.754
2023-10-24 14:43:21,946 (Training) Epoch: 9. Total loss: 1.595. Value loss: 0.145. Policy accuracy: 0.756
2023-10-24 14:44:58,922 (Training) Epoch: 10. Total loss: 1.594. Value loss: 0.144. Policy accuracy: 0.757
2023-10-24 14:52:31,192 (Evaluation) Win rate: 0.35
2023-10-24 14:52:31,192 (Evaluation) Model 1 wins: 17. Draws: 9. Model 2 wins: 14
2023-10-24 14:52:31,202 (Evaluation) Rejecting new model...
2023-10-24 14:52:31,225 

2023-10-24 14:52:31,226 Iteration 62
2023-10-24 15:25:40,289 (Self-play) Number of new training examples: 6482
2023-10-24 15:25:40,289 (Self-play) Number of total training examples: 418524
2023-10-24 15:25:40,289 (Self-play) Model 1 wins: 0. Draws: 55. Model 2 wins: 45
2023-10-24 15:27:18,354 (Training) Epoch: 1. Total loss: 1.635. Value loss: 0.175. Policy accuracy: 0.746
2023-10-24 15:28:56,406 (Training) Epoch: 2. Total loss: 1.625. Value loss: 0.167. Policy accuracy: 0.747
2023-10-24 15:30:34,681 (Training) Epoch: 3. Total loss: 1.618. Value loss: 0.162. Policy accuracy: 0.749
2023-10-24 15:32:13,503 (Training) Epoch: 4. Total loss: 1.616. Value loss: 0.160. Policy accuracy: 0.750
2023-10-24 15:33:51,567 (Training) Epoch: 5. Total loss: 1.614. Value loss: 0.158. Policy accuracy: 0.750
2023-10-24 15:35:30,114 (Training) Epoch: 6. Total loss: 1.610. Value loss: 0.156. Policy accuracy: 0.752
2023-10-24 15:37:06,738 (Training) Epoch: 7. Total loss: 1.608. Value loss: 0.156. Policy accuracy: 0.754
2023-10-24 15:38:46,468 (Training) Epoch: 8. Total loss: 1.606. Value loss: 0.153. Policy accuracy: 0.753
2023-10-24 15:40:24,369 (Training) Epoch: 9. Total loss: 1.603. Value loss: 0.152. Policy accuracy: 0.756
2023-10-24 15:42:01,808 (Training) Epoch: 10. Total loss: 1.602. Value loss: 0.152. Policy accuracy: 0.756
2023-10-24 15:53:57,616 (Evaluation) Win rate: 0.275
2023-10-24 15:53:57,617 (Evaluation) Model 1 wins: 12. Draws: 17. Model 2 wins: 11
2023-10-24 15:53:57,626 (Evaluation) Rejecting new model...
2023-10-24 15:53:57,651 

2023-10-24 15:53:57,652 Iteration 63
2023-10-24 16:29:11,208 (Self-play) Number of new training examples: 6932
2023-10-24 16:29:11,209 (Self-play) Number of total training examples: 425456
2023-10-24 16:29:11,209 (Self-play) Model 1 wins: 0. Draws: 62. Model 2 wins: 38
2023-10-24 16:30:51,078 (Training) Epoch: 1. Total loss: 1.647. Value loss: 0.188. Policy accuracy: 0.748
2023-10-24 16:32:29,323 (Training) Epoch: 2. Total loss: 1.637. Value loss: 0.178. Policy accuracy: 0.747
2023-10-24 16:34:08,673 (Training) Epoch: 3. Total loss: 1.631. Value loss: 0.172. Policy accuracy: 0.748
2023-10-24 16:35:47,491 (Training) Epoch: 4. Total loss: 1.624. Value loss: 0.168. Policy accuracy: 0.750
2023-10-24 16:37:27,237 (Training) Epoch: 5. Total loss: 1.620. Value loss: 0.165. Policy accuracy: 0.751
2023-10-24 16:39:06,252 (Training) Epoch: 6. Total loss: 1.618. Value loss: 0.165. Policy accuracy: 0.753
2023-10-24 16:40:43,896 (Training) Epoch: 7. Total loss: 1.615. Value loss: 0.161. Policy accuracy: 0.752
2023-10-24 16:42:22,039 (Training) Epoch: 8. Total loss: 1.613. Value loss: 0.161. Policy accuracy: 0.755
2023-10-24 16:44:01,877 (Training) Epoch: 9. Total loss: 1.609. Value loss: 0.159. Policy accuracy: 0.757
2023-10-24 16:45:41,618 (Training) Epoch: 10. Total loss: 1.607. Value loss: 0.158. Policy accuracy: 0.757
2023-10-24 16:54:15,010 (Evaluation) Win rate: 0.2
2023-10-24 16:54:15,010 (Evaluation) Model 1 wins: 12. Draws: 20. Model 2 wins: 8
2023-10-24 16:54:15,019 (Evaluation) Rejecting new model...
2023-10-24 16:54:15,042 

2023-10-24 16:54:15,043 Iteration 64
2023-10-24 17:27:05,797 (Self-play) Number of new training examples: 6412
2023-10-24 17:27:05,797 (Self-play) Number of total training examples: 431868
2023-10-24 17:27:05,797 (Self-play) Model 1 wins: 0. Draws: 50. Model 2 wins: 50
2023-10-24 17:28:45,982 (Training) Epoch: 1. Total loss: 1.645. Value loss: 0.185. Policy accuracy: 0.746
2023-10-24 17:30:25,937 (Training) Epoch: 2. Total loss: 1.635. Value loss: 0.176. Policy accuracy: 0.747
2023-10-24 17:32:04,043 (Training) Epoch: 3. Total loss: 1.628. Value loss: 0.170. Policy accuracy: 0.747
2023-10-24 17:33:43,063 (Training) Epoch: 4. Total loss: 1.625. Value loss: 0.167. Policy accuracy: 0.749
2023-10-24 17:35:22,286 (Training) Epoch: 5. Total loss: 1.620. Value loss: 0.164. Policy accuracy: 0.750
2023-10-24 17:37:01,604 (Training) Epoch: 6. Total loss: 1.618. Value loss: 0.163. Policy accuracy: 0.752
2023-10-24 17:38:41,933 (Training) Epoch: 7. Total loss: 1.614. Value loss: 0.160. Policy accuracy: 0.753
2023-10-24 17:40:21,783 (Training) Epoch: 8. Total loss: 1.612. Value loss: 0.159. Policy accuracy: 0.755
2023-10-24 17:42:01,952 (Training) Epoch: 9. Total loss: 1.610. Value loss: 0.158. Policy accuracy: 0.755
2023-10-24 17:43:40,402 (Training) Epoch: 10. Total loss: 1.608. Value loss: 0.157. Policy accuracy: 0.757
2023-10-24 17:51:34,127 (Evaluation) Win rate: 0.375
2023-10-24 17:51:34,127 (Evaluation) Model 1 wins: 22. Draws: 3. Model 2 wins: 15
2023-10-24 17:51:34,150 (Evaluation) Rejecting new model...
2023-10-24 17:51:34,184 

2023-10-24 17:51:34,185 Iteration 65
2023-10-24 18:28:29,323 (Self-play) Number of new training examples: 6898
2023-10-24 18:28:29,323 (Self-play) Number of total training examples: 438766
2023-10-24 18:28:29,323 (Self-play) Model 1 wins: 0. Draws: 62. Model 2 wins: 38
2023-10-24 18:30:09,523 (Training) Epoch: 1. Total loss: 1.659. Value loss: 0.198. Policy accuracy: 0.744
2023-10-24 18:31:48,843 (Training) Epoch: 2. Total loss: 1.646. Value loss: 0.186. Policy accuracy: 0.745
2023-10-24 18:33:27,728 (Training) Epoch: 3. Total loss: 1.636. Value loss: 0.178. Policy accuracy: 0.748
2023-10-24 18:35:08,713 (Training) Epoch: 4. Total loss: 1.631. Value loss: 0.175. Policy accuracy: 0.750
2023-10-24 18:36:49,018 (Training) Epoch: 5. Total loss: 1.630. Value loss: 0.173. Policy accuracy: 0.750
2023-10-24 18:38:29,333 (Training) Epoch: 6. Total loss: 1.624. Value loss: 0.168. Policy accuracy: 0.750
2023-10-24 18:40:09,810 (Training) Epoch: 7. Total loss: 1.620. Value loss: 0.166. Policy accuracy: 0.753
2023-10-24 18:41:49,388 (Training) Epoch: 8. Total loss: 1.618. Value loss: 0.165. Policy accuracy: 0.754
2023-10-24 18:43:29,176 (Training) Epoch: 9. Total loss: 1.615. Value loss: 0.164. Policy accuracy: 0.756
2023-10-24 18:45:10,183 (Training) Epoch: 10. Total loss: 1.612. Value loss: 0.162. Policy accuracy: 0.758
2023-10-24 18:53:26,254 (Evaluation) Win rate: 0.325
2023-10-24 18:53:26,254 (Evaluation) Model 1 wins: 14. Draws: 13. Model 2 wins: 13
2023-10-24 18:53:26,266 (Evaluation) Rejecting new model...
2023-10-24 18:53:26,290 

2023-10-24 18:53:26,291 Iteration 66
2023-10-24 19:28:32,409 (Self-play) Number of new training examples: 6954
2023-10-24 19:28:32,409 (Self-play) Number of total training examples: 445720
2023-10-24 19:28:32,409 (Self-play) Model 1 wins: 0. Draws: 63. Model 2 wins: 37
2023-10-24 19:30:13,674 (Training) Epoch: 1. Total loss: 1.658. Value loss: 0.196. Policy accuracy: 0.744
2023-10-24 19:31:55,118 (Training) Epoch: 2. Total loss: 1.646. Value loss: 0.185. Policy accuracy: 0.745
2023-10-24 19:33:36,043 (Training) Epoch: 3. Total loss: 1.636. Value loss: 0.177. Policy accuracy: 0.747
2023-10-24 19:35:17,902 (Training) Epoch: 4. Total loss: 1.631. Value loss: 0.173. Policy accuracy: 0.749
2023-10-24 19:36:59,921 (Training) Epoch: 5. Total loss: 1.626. Value loss: 0.169. Policy accuracy: 0.751
2023-10-24 19:38:41,185 (Training) Epoch: 6. Total loss: 1.624. Value loss: 0.168. Policy accuracy: 0.752
2023-10-24 19:40:20,198 (Training) Epoch: 7. Total loss: 1.618. Value loss: 0.165. Policy accuracy: 0.755
2023-10-24 19:42:02,228 (Training) Epoch: 8. Total loss: 1.617. Value loss: 0.164. Policy accuracy: 0.754
2023-10-24 19:43:44,968 (Training) Epoch: 9. Total loss: 1.613. Value loss: 0.162. Policy accuracy: 0.757
2023-10-24 19:45:25,734 (Training) Epoch: 10. Total loss: 1.611. Value loss: 0.161. Policy accuracy: 0.758
2023-10-24 19:53:49,731 (Evaluation) Win rate: 0.4
2023-10-24 19:53:49,731 (Evaluation) Model 1 wins: 15. Draws: 9. Model 2 wins: 16
2023-10-24 19:53:49,743 (Evaluation) Rejecting new model...
2023-10-24 19:53:49,768 

2023-10-24 19:53:49,769 Iteration 67
2023-10-24 20:27:22,492 (Self-play) Number of new training examples: 6636
2023-10-24 20:27:22,493 (Self-play) Number of total training examples: 452356
2023-10-24 20:27:22,493 (Self-play) Model 1 wins: 0. Draws: 56. Model 2 wins: 44
2023-10-24 20:29:02,252 (Training) Epoch: 1. Total loss: 1.655. Value loss: 0.194. Policy accuracy: 0.745
2023-10-24 20:30:42,226 (Training) Epoch: 2. Total loss: 1.643. Value loss: 0.183. Policy accuracy: 0.746
2023-10-24 20:32:22,663 (Training) Epoch: 3. Total loss: 1.635. Value loss: 0.176. Policy accuracy: 0.747
2023-10-24 20:34:03,633 (Training) Epoch: 4. Total loss: 1.630. Value loss: 0.171. Policy accuracy: 0.749
2023-10-24 20:35:44,750 (Training) Epoch: 5. Total loss: 1.625. Value loss: 0.169. Policy accuracy: 0.752
2023-10-24 20:37:25,610 (Training) Epoch: 6. Total loss: 1.622. Value loss: 0.167. Policy accuracy: 0.753
2023-10-24 20:39:05,283 (Training) Epoch: 7. Total loss: 1.618. Value loss: 0.164. Policy accuracy: 0.754
2023-10-24 20:40:45,369 (Training) Epoch: 8. Total loss: 1.615. Value loss: 0.163. Policy accuracy: 0.755
2023-10-24 20:42:25,936 (Training) Epoch: 9. Total loss: 1.613. Value loss: 0.161. Policy accuracy: 0.756
2023-10-24 20:44:06,616 (Training) Epoch: 10. Total loss: 1.611. Value loss: 0.160. Policy accuracy: 0.757
2023-10-24 20:57:35,282 (Evaluation) Win rate: 0.275
2023-10-24 20:57:35,282 (Evaluation) Model 1 wins: 14. Draws: 15. Model 2 wins: 11
2023-10-24 20:57:35,293 (Evaluation) Rejecting new model...
2023-10-24 20:57:35,316 

2023-10-24 20:57:35,317 Iteration 68
2023-10-24 21:30:05,098 (Self-play) Number of new training examples: 6446
2023-10-24 21:30:05,098 (Self-play) Number of total training examples: 458802
2023-10-24 21:30:05,098 (Self-play) Model 1 wins: 0. Draws: 53. Model 2 wins: 47
2023-10-24 21:31:46,268 (Training) Epoch: 1. Total loss: 1.654. Value loss: 0.192. Policy accuracy: 0.744
2023-10-24 21:33:28,311 (Training) Epoch: 2. Total loss: 1.642. Value loss: 0.181. Policy accuracy: 0.745
2023-10-24 21:35:09,590 (Training) Epoch: 3. Total loss: 1.634. Value loss: 0.175. Policy accuracy: 0.748
2023-10-24 21:36:51,238 (Training) Epoch: 4. Total loss: 1.627. Value loss: 0.170. Policy accuracy: 0.751
2023-10-24 21:38:32,871 (Training) Epoch: 5. Total loss: 1.622. Value loss: 0.166. Policy accuracy: 0.752
2023-10-24 21:40:15,395 (Training) Epoch: 6. Total loss: 1.618. Value loss: 0.164. Policy accuracy: 0.754
2023-10-24 21:41:59,503 (Training) Epoch: 7. Total loss: 1.616. Value loss: 0.163. Policy accuracy: 0.755
2023-10-24 21:43:41,707 (Training) Epoch: 8. Total loss: 1.614. Value loss: 0.162. Policy accuracy: 0.756
2023-10-24 21:45:23,627 (Training) Epoch: 9. Total loss: 1.612. Value loss: 0.160. Policy accuracy: 0.757
2023-10-24 21:47:06,360 (Training) Epoch: 10. Total loss: 1.611. Value loss: 0.159. Policy accuracy: 0.755
2023-10-24 21:58:28,276 (Evaluation) Win rate: 0.45
2023-10-24 21:58:28,277 (Evaluation) Model 1 wins: 13. Draws: 9. Model 2 wins: 18
2023-10-24 21:58:28,286 (Evaluation) Rejecting new model...
2023-10-24 21:58:28,311 

2023-10-24 21:58:28,313 Iteration 69
2023-10-24 22:33:09,742 (Self-play) Number of new training examples: 6960
2023-10-24 22:33:09,743 (Self-play) Number of total training examples: 465762
2023-10-24 22:33:09,743 (Self-play) Model 1 wins: 0. Draws: 63. Model 2 wins: 37
2023-10-24 22:34:52,893 (Training) Epoch: 1. Total loss: 1.653. Value loss: 0.191. Policy accuracy: 0.744
2023-10-24 22:36:35,708 (Training) Epoch: 2. Total loss: 1.639. Value loss: 0.179. Policy accuracy: 0.746
2023-10-24 22:38:20,940 (Training) Epoch: 3. Total loss: 1.632. Value loss: 0.172. Policy accuracy: 0.747
2023-10-24 22:40:04,878 (Training) Epoch: 4. Total loss: 1.626. Value loss: 0.168. Policy accuracy: 0.748
2023-10-24 22:41:47,961 (Training) Epoch: 5. Total loss: 1.623. Value loss: 0.166. Policy accuracy: 0.751
2023-10-24 22:43:31,953 (Training) Epoch: 6. Total loss: 1.617. Value loss: 0.163. Policy accuracy: 0.754
2023-10-24 22:45:15,089 (Training) Epoch: 7. Total loss: 1.615. Value loss: 0.162. Policy accuracy: 0.754
2023-10-24 22:47:00,243 (Training) Epoch: 8. Total loss: 1.611. Value loss: 0.159. Policy accuracy: 0.755
2023-10-24 22:48:44,947 (Training) Epoch: 9. Total loss: 1.610. Value loss: 0.158. Policy accuracy: 0.757
2023-10-24 22:50:30,019 (Training) Epoch: 10. Total loss: 1.608. Value loss: 0.157. Policy accuracy: 0.758
2023-10-24 22:57:57,652 (Evaluation) Win rate: 0.55
2023-10-24 22:57:57,652 (Evaluation) Model 1 wins: 1. Draws: 17. Model 2 wins: 22
2023-10-24 22:57:57,663 (Evaluation) Accepting new model...
2023-10-24 22:57:57,688 

2023-10-24 22:57:57,688 Iteration 70
2023-10-24 23:32:13,077 (Self-play) Number of new training examples: 6864
2023-10-24 23:32:13,077 (Self-play) Number of total training examples: 472626
2023-10-24 23:32:13,077 (Self-play) Model 1 wins: 0. Draws: 62. Model 2 wins: 38
2023-10-24 23:33:57,576 (Training) Epoch: 1. Total loss: 1.618. Value loss: 0.168. Policy accuracy: 0.758
2023-10-24 23:35:43,206 (Training) Epoch: 2. Total loss: 1.614. Value loss: 0.165. Policy accuracy: 0.759
2023-10-24 23:37:29,534 (Training) Epoch: 3. Total loss: 1.611. Value loss: 0.163. Policy accuracy: 0.760
2023-10-24 23:39:15,422 (Training) Epoch: 4. Total loss: 1.608. Value loss: 0.161. Policy accuracy: 0.761
2023-10-24 23:41:01,298 (Training) Epoch: 5. Total loss: 1.608. Value loss: 0.161. Policy accuracy: 0.762
2023-10-24 23:42:46,790 (Training) Epoch: 6. Total loss: 1.606. Value loss: 0.160. Policy accuracy: 0.763
2023-10-24 23:44:33,541 (Training) Epoch: 7. Total loss: 1.604. Value loss: 0.159. Policy accuracy: 0.763
2023-10-24 23:46:19,441 (Training) Epoch: 8. Total loss: 1.601. Value loss: 0.157. Policy accuracy: 0.765
2023-10-24 23:48:05,221 (Training) Epoch: 9. Total loss: 1.602. Value loss: 0.157. Policy accuracy: 0.764
2023-10-24 23:49:50,174 (Training) Epoch: 10. Total loss: 1.600. Value loss: 0.156. Policy accuracy: 0.764
2023-10-24 23:56:20,832 (Evaluation) Win rate: 0.325
2023-10-24 23:56:20,833 (Evaluation) Model 1 wins: 17. Draws: 10. Model 2 wins: 13
2023-10-24 23:56:20,844 (Evaluation) Rejecting new model...
2023-10-24 23:56:20,869 

2023-10-24 23:56:20,870 Iteration 71
