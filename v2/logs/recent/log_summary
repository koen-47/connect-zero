2023-09-09 01:22:20,880 Iteration 1
2023-09-09 01:22:54,149 (Self Play) Number of training examples: 168
2023-09-09 01:22:54,400 (Training) Epoch: 1. Total loss: 2.011. Value loss: 0.001. Policy loss: 0.219
2023-09-09 01:22:54,485 (Training) Epoch: 2. Total loss: 1.990. Value loss: 0.000. Policy loss: 0.320
2023-09-09 01:22:54,567 (Training) Epoch: 3. Total loss: 1.967. Value loss: 0.000. Policy loss: 0.352
2023-09-09 01:22:54,649 (Training) Epoch: 4. Total loss: 1.941. Value loss: 0.000. Policy loss: 0.375
2023-09-09 01:22:54,680 (Training) Epoch: 5. Total loss: 1.887. Value loss: 0.000. Policy loss: 0.547
2023-09-09 01:22:54,703 (Training) Epoch: 6. Total loss: 1.866. Value loss: 0.000. Policy loss: 0.594
2023-09-09 01:22:54,729 (Training) Epoch: 7. Total loss: 1.895. Value loss: 0.000. Policy loss: 0.508
2023-09-09 01:22:54,755 (Training) Epoch: 8. Total loss: 1.851. Value loss: 0.000. Policy loss: 0.570
2023-09-09 01:22:54,776 (Training) Epoch: 9. Total loss: 1.849. Value loss: 0.000. Policy loss: 0.562
2023-09-09 01:22:54,799 (Training) Epoch: 10. Total loss: 1.777. Value loss: 0.000. Policy loss: 0.719
2023-09-09 01:23:20,244 (Arena) Results (pwins/nwins/draws) => (0, 1, 1)
2023-09-09 01:23:20,244 (Arena) Rejecting new model.
2023-09-09 01:23:20,271 

2023-09-09 01:23:20,272 Iteration 2
